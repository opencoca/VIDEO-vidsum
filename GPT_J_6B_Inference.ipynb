{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "GPT-J-6B Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "590600fc047d46a39493fe79a8f9164c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f2e93a38a3143caaa13ad172d6414f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d29a3417f004299840b4ca900c5a6ac",
              "IPY_MODEL_2f06b0edd7714e5abe7eda0c5048147f"
            ]
          }
        },
        "0f2e93a38a3143caaa13ad172d6414f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d29a3417f004299840b4ca900c5a6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c6370ca77a9a455b99fdb2fe5038dddc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_454765c2d62846098dcc21d4daffbfab"
          }
        },
        "2f06b0edd7714e5abe7eda0c5048147f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4dfb536ddebd45d88ab613e20f2dd505",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.99M/0.99M [00:01&lt;00:00, 577kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9fab937c4e046c494e8dbea614d631c"
          }
        },
        "c6370ca77a9a455b99fdb2fe5038dddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "454765c2d62846098dcc21d4daffbfab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dfb536ddebd45d88ab613e20f2dd505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9fab937c4e046c494e8dbea614d631c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "928f4faac3ac4a5386e8b8b957a89d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6abc3c3ea9a04727938ea90e97c0ca4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b7c437aba2e42b08ea846b9287db081",
              "IPY_MODEL_1c1e47903d6044cba00373542ae64b4e"
            ]
          }
        },
        "6abc3c3ea9a04727938ea90e97c0ca4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b7c437aba2e42b08ea846b9287db081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a99894c4aeef4b8a8a606f700e8f8cf0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_330889334fcb4f79a6e7dc9439295a2b"
          }
        },
        "1c1e47903d6044cba00373542ae64b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c72146da72d4bc2bef021afb29f5878",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 446k/446k [00:00&lt;00:00, 1.06MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02f203be21704e57ace22a4a9fcca5ac"
          }
        },
        "a99894c4aeef4b8a8a606f700e8f8cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "330889334fcb4f79a6e7dc9439295a2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c72146da72d4bc2bef021afb29f5878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02f203be21704e57ace22a4a9fcca5ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "592e2011a04d4855ab80c627168c776b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6cbec02e8ea34eec810629455fd40953",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0cdfb0957a674bb2bee76e28cb62dd4d",
              "IPY_MODEL_94a40750b7514b77822fe21f0a2203b6"
            ]
          }
        },
        "6cbec02e8ea34eec810629455fd40953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cdfb0957a674bb2bee76e28cb62dd4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8325cc6afa1349ac911f0b5cbc101d33",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b051dd566c7428b8b4a4feb2eab8578"
          }
        },
        "94a40750b7514b77822fe21f0a2203b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a91864eac00a4dfbad438af223ee6c78",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.29M/1.29M [00:00&lt;00:00, 1.53MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cabbfd244baf40e4a30c3f40c822b991"
          }
        },
        "8325cc6afa1349ac911f0b5cbc101d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b051dd566c7428b8b4a4feb2eab8578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a91864eac00a4dfbad438af223ee6c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cabbfd244baf40e4a30c3f40c822b991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7802d1ceee7d43bf83fb69edb8a2fa22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73fd513b20484e99b88e079222ce86b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_acc6c20257f047f3b3db3102cb74ef02",
              "IPY_MODEL_4ea0beba0b2d40558f0f9da15f81bef0"
            ]
          }
        },
        "73fd513b20484e99b88e079222ce86b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acc6c20257f047f3b3db3102cb74ef02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c93d7e2c42841f4ac4c0e41d2ee6865",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9522e10bd8143eba366ab44e65a8c8c"
          }
        },
        "4ea0beba0b2d40558f0f9da15f81bef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_de4df379668e46f2b1f22f6b6ac96940",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 17.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_728c9dcbcd8f4593b2c93faf2629c978"
          }
        },
        "1c93d7e2c42841f4ac4c0e41d2ee6865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9522e10bd8143eba366ab44e65a8c8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de4df379668e46f2b1f22f6b6ac96940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "728c9dcbcd8f4593b2c93faf2629c978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/opencoca/vidsum/blob/master/GPT_J_6B_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHIJVqHsh4An"
      },
      "source": [
        "# GPT-J-6B Inference \n",
        "\n",
        "This notebook explores how to work with the [GPT-J-6B model](https://github.com/kingoflolz/mesh-transformer-jax/#GPT-J-6B). See the link for more details about the model, including evaluation metrics and credits.\n",
        "\n",
        "Please note it takes ~10 minutes for this notebook to fully spin up. Sometimes you will runout of ram when attempting to setup the model. If this happens factory restart the runtime and try again. If it contines to happen ...\n",
        "\n",
        "Start this notebok by clicking `Runtime > Run all` or clicking `⌘/Ctrl+F9`. Use `⌘` on Mac and `Ctrl` on Windows and Linux. \n",
        "\n",
        "Keep an eye on this as it spins up. Google likes to make sure you are not a bot and will stop things if you ignore the \"I'm not a robot\" popup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CMw_dSQKfhT"
      },
      "source": [
        "## Prepare it to be used\n",
        "\n",
        "### Install Dependencies\n",
        "\n",
        "First we download the model and install some dependencies. This step takes at least 5 minutes (possibly longer depending on server load).\n",
        "\n",
        "!!! **Make sure you are using a TPU runtime!** !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdkgIa72_2FT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d80a4dc-1fcb-4bf7-c177-6e5dc6ed4180"
      },
      "source": [
        "#@title Mount Google Drive and clone project repo\n",
        "#@markdown Not having to reinstall all libs speeds up relaunch immensely\n",
        "!git clone -q https://github.com/kingoflolz/mesh-transformer-jax.git\n",
        "\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0,nb_path)\n",
        "\n",
        "pk_path = '/content/site-packages'\n",
        "os.makedirs('/content/drive/My Drive/Colab Notebooks/site-packages', exist_ok=True)\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks/site-packages', pk_path)\n",
        "sys.path.insert(0,pk_path)\n",
        "\n",
        "os.symlink('/content/notebooks/step_383500_slim.tar.zstd', '/content/step_383500_slim.tar.zstd')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7xAFw-LOYfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be48c653-33ed-47cb-cfc7-5c362fbefe82"
      },
      "source": [
        "#@title Install GPT-J-6B Network\n",
        "#@markdown So long as you already have a copy of GPT-J in your Google Drive this is a fast process. If the is is the first time it can take almost half an hour if https://the-eye.eu is flooded with traffic.\n",
        "!apt-get install -qq zstd\n",
        "\n",
        "# the \"slim\" version contain only bf16 weights and no optimizer parameters, which minimizes bandwidth and memory\n",
        "!echo \"Getting https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd this can take ~6-20 min.\"\n",
        "!time wget  -nc -c https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
        "\n",
        "!time tar -I zstd -xf step_383500_slim.tar.zstd\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package zstd.\n",
            "(Reading database ... 155219 files and directories currently installed.)\n",
            "Preparing to unpack .../zstd_1.3.3+dfsg-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking zstd (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "Setting up zstd (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Getting https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd this can take ~6-20 min.\n",
            "File ‘step_383500_slim.tar.zstd’ already there; not retrieving.\n",
            "\n",
            "\n",
            "real\t0m0.011s\n",
            "user\t0m0.005s\n",
            "sys\t0m0.001s\n",
            "\n",
            "real\t2m47.166s\n",
            "user\t0m31.526s\n",
            "sys\t0m29.978s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKUWvMaIyXJe"
      },
      "source": [
        "#@title Install Tensorflow\n",
        "#@markdown restart once this has run\n",
        "\n",
        "!pip install --target=$pk_path tensorflow==2.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KqQLCc244hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a772ae67-d3ca-4e3c-b953-af7575d6451a"
      },
      "source": [
        "#@title Install GPT-J-6B Inference OpenCo's requirements.txt\n",
        "#@markdown restart once this has run\n",
        "\n",
        "!wget -O mesh-transformer-jax/requirements.txt https://gist.githubusercontent.com/opencoca/ea36cfdf091c93df337f36951fa93a50/raw/83f7e5246a0c7ed873569e1edab93ef289252f1e/requirements.txt\n",
        "\n",
        "!echo \"Quietly installing GPT-J-6B Inference OpenCo's requirements.txt\"\n",
        "!pip -q install --target=$pk_path -r mesh-transformer-jax/requirements.txt\n",
        "\n",
        "# jax 0.2.12 is required due to a regression with xmap in 0.2.13\n",
        "!pip -q install --target=$pk_path mesh-transformer-jax/ jax==0.2.12\n",
        "!pip -q install --target=$pk_path optax==0.0.9 transformers==4.12.3 dm-haiku==0.0.5 einops==0.3.2 jax==0.2.12 ray==1.8.0 \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lm-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bleurt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.45.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 1.3.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Building wheel for mesh-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT1XmBc7BHwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "defec53d-8065-4e91-82ee-6da7980a182c"
      },
      "source": [
        "#@title Re-Install Tensorflow\n",
        "#@markdown restart once this has run\n",
        "\n",
        "!pip install --target=$pk_path tensorflow==2.5.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.5.0\n",
            "  Using cached tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.12.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Using cached grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.6.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.12.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.37.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.6.0)\n",
            "Installing collected packages: grpcio, tensorflow-estimator, tensorflow\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.41.1\n",
            "    Uninstalling grpcio-1.41.1:\n",
            "      Successfully uninstalled grpcio-1.41.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.2\n",
            "    Uninstalling tensorflow-2.6.2:\n",
            "      Successfully uninstalled tensorflow-2.6.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.6.0 requires tensorflow<2.7,>=2.6.0, but you have tensorflow 2.5.0 which is incompatible.\n",
            "lm-eval 0.0.1 requires tensorflow-estimator==2.6.0, but you have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n",
            "Successfully installed grpcio-1.34.1 tensorflow-2.5.0 tensorflow-estimator-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "TeuOpunQpZCr",
        "outputId": "ad47144b-36aa-4ca4-f08d-29f2ea0207d8"
      },
      "source": [
        "#@title Re-Install GPT-J-6B Inference OpenCo's requirements.txt\n",
        "#@markdown restart once this has run\n",
        "\n",
        "!wget -O mesh-transformer-jax/requirements.txt https://gist.githubusercontent.com/opencoca/ea36cfdf091c93df337f36951fa93a50/raw/83f7e5246a0c7ed873569e1edab93ef289252f1e/requirements.txt\n",
        "\n",
        "!echo \"Quietly installing GPT-J-6B Inference OpenCo's requirements.txt\"\n",
        "!pip -q install --target=$pk_path -r mesh-transformer-jax/requirements.txt\n",
        "\n",
        "# jax 0.2.12 is required due to a regression with xmap in 0.2.13\n",
        "!pip -q install --target=$pk_path mesh-transformer-jax/ jax==0.2.12\n",
        "!pip -q install --target=$pk_path optax==0.0.9 transformers==4.12.3 dm-haiku==0.0.5 einops==0.3.2 jax==0.2.12 ray==1.8.0 \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-11 15:40:20--  https://gist.githubusercontent.com/opencoca/ea36cfdf091c93df337f36951fa93a50/raw/83f7e5246a0c7ed873569e1edab93ef289252f1e/requirements.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 414 [text/plain]\n",
            "Saving to: ‘mesh-transformer-jax/requirements.txt’\n",
            "\n",
            "\r          mesh-tran   0%[                    ]       0  --.-KB/s               \rmesh-transformer-ja 100%[===================>]     414  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-11 15:40:20 (24.9 MB/s) - ‘mesh-transformer-jax/requirements.txt’ saved [414/414]\n",
            "\n",
            "Quietly installing GPT-J-6B Inference OpenCo's requirements.txt\n",
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Building wheel for mesh-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO1UXepF-0Uq"
      },
      "source": [
        "## Setup Model\n",
        "\n",
        "Make sure to  restart your runtime for this will work reliably. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex0qJgaueZtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fce9991-cee5-4c05-b70c-58b7cd724db1"
      },
      "source": [
        "#@title Setup JAX for TPU use\n",
        "import os\n",
        "import requests \n",
        "from jax.config import config\n",
        "\n",
        "colab_tpu_addr = os.environ['COLAB_TPU_ADDR'].split(':')[0]\n",
        "url = f'http://{colab_tpu_addr}:8475/requestversion/tpu_driver0.1_dev20210607'\n",
        "print(url)\n",
        "requests.post(url)\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://10.96.221.146:8475/requestversion/tpu_driver0.1_dev20210607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIgUVdFLe4A8"
      },
      "source": [
        "Sometimes the next step errors for some reason, just run it again ¯\\\\\\_(ツ)\\_/¯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A5IGYSaeze3"
      },
      "source": [
        "#@title Import libraries\n",
        "#@markdown If this fails reinstall OpenCo's requirments and attempt Model Setup again.\n",
        "import time\n",
        "\n",
        "import jax\n",
        "from jax.experimental import maps\n",
        "import numpy as np\n",
        "import optax\n",
        "import transformers\n",
        "\n",
        "from mesh_transformer.checkpoint import read_ckpt\n",
        "from mesh_transformer.sampling import nucleaus_sample\n",
        "from mesh_transformer.transformer_shard import CausalTransformer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAgKq-X2kmba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "590600fc047d46a39493fe79a8f9164c",
            "0f2e93a38a3143caaa13ad172d6414f5",
            "9d29a3417f004299840b4ca900c5a6ac",
            "2f06b0edd7714e5abe7eda0c5048147f",
            "c6370ca77a9a455b99fdb2fe5038dddc",
            "454765c2d62846098dcc21d4daffbfab",
            "4dfb536ddebd45d88ab613e20f2dd505",
            "f9fab937c4e046c494e8dbea614d631c",
            "928f4faac3ac4a5386e8b8b957a89d80",
            "6abc3c3ea9a04727938ea90e97c0ca4b",
            "7b7c437aba2e42b08ea846b9287db081",
            "1c1e47903d6044cba00373542ae64b4e",
            "a99894c4aeef4b8a8a606f700e8f8cf0",
            "330889334fcb4f79a6e7dc9439295a2b",
            "9c72146da72d4bc2bef021afb29f5878",
            "02f203be21704e57ace22a4a9fcca5ac",
            "592e2011a04d4855ab80c627168c776b",
            "6cbec02e8ea34eec810629455fd40953",
            "0cdfb0957a674bb2bee76e28cb62dd4d",
            "94a40750b7514b77822fe21f0a2203b6",
            "8325cc6afa1349ac911f0b5cbc101d33",
            "4b051dd566c7428b8b4a4feb2eab8578",
            "a91864eac00a4dfbad438af223ee6c78",
            "cabbfd244baf40e4a30c3f40c822b991",
            "7802d1ceee7d43bf83fb69edb8a2fa22",
            "73fd513b20484e99b88e079222ce86b7",
            "acc6c20257f047f3b3db3102cb74ef02",
            "4ea0beba0b2d40558f0f9da15f81bef0",
            "1c93d7e2c42841f4ac4c0e41d2ee6865",
            "c9522e10bd8143eba366ab44e65a8c8c",
            "de4df379668e46f2b1f22f6b6ac96940",
            "728c9dcbcd8f4593b2c93faf2629c978"
          ]
        },
        "outputId": "b4abc6cc-3fe3-4c15-ca5b-6fd6a4eaee4a"
      },
      "source": [
        "#@title Set Network Parameters \n",
        "params = {\n",
        "  \"layers\": 28,\n",
        "  \"d_model\": 4096,\n",
        "  \"n_heads\": 16,\n",
        "  \"n_vocab\": 50400,\n",
        "  \"norm\": \"layernorm\",\n",
        "  \"pe\": \"rotary\",\n",
        "  \"pe_rotary_dims\": 64,\n",
        "\n",
        "  \"seq\": 2048,\n",
        "  \"cores_per_replica\": 8,\n",
        "  \"per_replica_batch\": 1,\n",
        "}\n",
        "\n",
        "per_replica_batch = params[\"per_replica_batch\"]\n",
        "cores_per_replica = params[\"cores_per_replica\"]\n",
        "seq = params[\"seq\"]\n",
        "\n",
        "\n",
        "params[\"sampler\"] = nucleaus_sample\n",
        "\n",
        "# here we \"remove\" the optimizer parameters from the model (as we don't need them for inference)\n",
        "params[\"optimizer\"] = optax.scale(0)\n",
        "\n",
        "mesh_shape = (jax.device_count() // cores_per_replica, cores_per_replica)\n",
        "devices = np.array(jax.devices()).reshape(mesh_shape)\n",
        "\n",
        "maps.thread_resources.env = maps.ResourceEnv(maps.Mesh(devices, ('dp', 'mp')))\n",
        "\n",
        "tokenizer = transformers.GPT2TokenizerFast.from_pretrained('gpt2')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "590600fc047d46a39493fe79a8f9164c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "928f4faac3ac4a5386e8b8b957a89d80",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "592e2011a04d4855ab80c627168c776b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7802d1ceee7d43bf83fb69edb8a2fa22",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "T7kJZTkVQ2CZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a4a7b1-124a-4dfd-95a1-800c15b98c5f"
      },
      "source": [
        "#@title Install Tracery \n",
        "#@markdown Tracery is a gramar for spining articles, stories, and text in general. https://github.com/aparrish/pytracery\n",
        "!pip install tracery"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tracery\n",
            "  Downloading tracery-0.1.1.tar.gz (8.1 kB)\n",
            "Building wheels for collected packages: tracery\n",
            "  Building wheel for tracery (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tracery: filename=tracery-0.1.1-py3-none-any.whl size=7696 sha256=baca5faf54c64412d46e9385b240cb69d9163110a194f6d1010befa33f979292\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/38/48/da02ec3e9b648c4b52ffbdae69d9a1434e5cf621435f503486\n",
            "Successfully built tracery\n",
            "Installing collected packages: tracery\n",
            "Successfully installed tracery-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xgsL0IFTZt0",
        "cellView": "form"
      },
      "source": [
        "#@title Tidy things up\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwNETD2Uk8nu",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378533f0-753e-4a6a-cb2b-8c4c44590523"
      },
      "source": [
        "#@title Create the network\n",
        "#@markdown ...loading neural weights from the downloaded files. \n",
        "#@markdown\n",
        "#@markdown  > *This can take around 5 minutes.*\n",
        "total_batch = per_replica_batch * jax.device_count() // cores_per_replica\n",
        "\n",
        "network = CausalTransformer(params)\n",
        "\n",
        "network.state = read_ckpt(network.state, \"step_383500/\", devices.shape[1])\n",
        "\n",
        "network.state = network.move_xmap(network.state, np.zeros(cores_per_replica))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/experimental/maps.py:412: UserWarning: xmap is an experimental feature and probably has bugs!\n",
            "  warn(\"xmap is an experimental feature and probably has bugs!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key shape (8, 2)\n",
            "in shape (1, 2048)\n",
            "dp 1\n",
            "mp 8\n",
            "Total parameters: 6053381344\n",
            "read from disk/gcs in 98.0927s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-eT7Sw6if4J"
      },
      "source": [
        "# Run Model\n",
        "\n",
        "Finally, we are ready to infer with the model! The first sample takes around a minute due to compilation, but after that it should only take about 10 seconds per sample.\n",
        "\n",
        "Feel free to mess with the different sampling parameters (top_p and temp), as well as the length of the generations (gen_len, causes a recompile when initially changed - recompiles will be cached).\n",
        "\n",
        "You can also change other things like per_replica_batch in the previous cells to change how many generations are done in parallel. A larger batch has higher latency but higher throughput when measured in tokens generated/s. This is useful for doing things like best-of-n cherry picking.\n",
        "\n",
        "*Tip for best results: Make sure your prompt does not have any trailing spaces, which tend to confuse the model due to the BPE tokenization used during training.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuZq54dh8opl",
        "cellView": "form"
      },
      "source": [
        "#@markdown We allow for text wrapping of whitespace via css injection.\n",
        "\n",
        "# allow text wrapping in generated output: https://stackoverflow.com/a/61401455\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVzs2TYlvYeX",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9d15ad5c-a940-404c-9cb0-65ce1c665f73"
      },
      "source": [
        "#@title Define our infer function. \n",
        "def infer(context, top_p=0.9, temp=1.0, gen_len=256):\n",
        "    tokens = tokenizer.encode(context)\n",
        "\n",
        "    provided_ctx = len(tokens)\n",
        "    pad_amount = seq - provided_ctx\n",
        "\n",
        "    padded_tokens = np.pad(tokens, ((pad_amount, 0),)).astype(np.uint32)\n",
        "    batched_tokens = np.array([padded_tokens] * total_batch)\n",
        "    length = np.ones(total_batch, dtype=np.uint32) * len(tokens)\n",
        "\n",
        "    start = time.time()\n",
        "    output = network.generate(batched_tokens, length, gen_len, {\"top_p\": np.ones(total_batch) * top_p, \"temp\": np.ones(total_batch) * temp})\n",
        "\n",
        "    samples = []\n",
        "    decoded_tokens = output[1][0]\n",
        "\n",
        "    for o in decoded_tokens[:, :, 0]:\n",
        "      samples.append(f\"\\033[1m{context}\\033[0m{tokenizer.decode(o)}\")\n",
        "\n",
        "    #print(f\"completion done in {time.time() - start:06}s\")\n",
        "    #this should instead be added to the object returned infered.samples and infered.completion_time\n",
        "    return samples\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjWw1zkEOP8z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "cellView": "form",
        "outputId": "68a852f0-90a6-46cf-b355-1ab874f779fb"
      },
      "source": [
        "#@title Warmup our inference engine \n",
        "#@markdown The first time that infrences are run for a given length takes imensly longer than on repeated runs. For this reason we spin up the inference engine with a few sample runs. With this out of the way we can quickly experiment with our infrence engine. \n",
        "\n",
        "context = \"\"\"\n",
        "# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL\n",
        "## SPACES CITÉ MULTIMÉDIA\n",
        "\n",
        "The Old Port of Montreal is a\"\"\"\n",
        "\n",
        "for i in [32,64,96,128,256,512,1024,2048]:\n",
        "  print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
        "  print(f\" ## Infering context with a gen_len of {i} this should take ~{i/24} sec. when run again ##\")\n",
        "  print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
        "  print(infer(context, gen_len=i)[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 32 this should take ~1.3333333333333333 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m\n",
            "# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL\n",
            "## SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "The Old Port of Montreal is a\u001b[0m busy heart of the city, a working-class neighborhood that is a working port and long an emblem of Montreal as a working-class city. In this case\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 64 this should take ~2.6666666666666665 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m\n",
            "# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL\n",
            "## SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "The Old Port of Montreal is a\u001b[0m neighborhood in transition. The old commercial center is slowly giving way to a shiny new condo district, while old urban warehouses, empty lots, and empty factories are transforming into artists studios, a handful of trendy lofts and condos, and lofts of convenience, very much in line with the national trend of the dot.com\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 96 this should take ~4.0 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m\n",
            "# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL\n",
            "## SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "The Old Port of Montreal is a\u001b[0m microcosm of the city. Walk the streets and find the history. Visit the business districts and you'll find the people, who are busy growing and doing business in Montreal. Visit the Montreal North Solidarity Camps and you'll find the spirit and strength of the people who are fighting a government that wants to close their neighbourhood. Visit the non-profit industry in the Old Port and you'll find the hands-on people who help fill the gaps that we see in our\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 128 this should take ~5.333333333333333 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m\n",
            "# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL\n",
            "## SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "The Old Port of Montreal is a\u001b[0m major tourist destination, but until recently it has been quite bereft of media venues. Within this historic site, there have been several efforts to establish new cultural spaces, but few have really taken hold and been sustained. Today, the Old Port is home to fewer than half as many media sites as are found in other major cities such as London, New York, or Paris, despite the fact that it has twice the population of those cities. To date, the Montreal-based development agency, SPACE (Société par Action Culturelle), has been the only one to actually transform the physical fabric of the Old Port into a museum\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 256 this should take ~10.666666666666666 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m\n",
            "# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL\n",
            "## SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "The Old Port of Montreal is a\u001b[0m unique destination in all of Canada. It is still alive and kicking and full of life and all types of people. This way of living and making in the Old Port of Montreal is a way of life for people who live here. It has some unique characteristics. The Old Port of Montreal is large, has many parks and pedestrian spaces and has close to 600 historic buildings. It is located on an isthmus, so it is part of the same peninsula as the Island of Montreal. At the other end of the Old Port, there is another smaller part, with stores and businesses and restaurants and so on, all on the water. At its heart, the Old Port is a working harbour. It is still a working harbour and people come here to work and they stay here. There are many opportunities for work and to live in this neighbourhood. This neighbourhood has more commercial and industrial space than anywhere else in Montreal. You can find many restaurants, food stores, bookstores and places where you can make things. On the streets, there are shops of all types. There are cultural centres, hotels, internet cafés, churches and different kinds of clubs. In the other part of the neighbourhood, you can find cultural centres, restaurants, a library and services. This neighbourhood is full\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 512 this should take ~21.333333333333332 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m\n",
            "# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL\n",
            "## SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "The Old Port of Montreal is a\u001b[0m veritable repository of more than a century of history, and it was once the hub of the world's great trade routes. This is where you'll find the most popular cruise ships mooring, but it's also the home of one of the city's major festivals: the World's Biggest Street Party in April. Set up in the Old Port is one of the city's most dynamic new forms of urban development: the Site de Québec Innovation.\n",
            "\n",
            "ON THE ROUTE\n",
            "\n",
            "As you make your way along St-Joseph Street, you can't help but notice the continuous succession of old buildings that date from the late 19th and early 20th centuries. This, however, is not only about history; it is also about how this new project makes use of them to form a new public space that offers Montrealers a unique experience.\n",
            "\n",
            "GETTING HERE\n",
            "\n",
            "If you're arriving by car, take Exit 8 off Autoroute 15. Turn left and follow the signs to Autoroute Deux-Montagnes. There's a commuter parking lot on the right just after the bridge and on the left in the Old Port.\n",
            "\n",
            "Another option is to catch the southbound No. 4 metro line. Just get off the train at the Old Port and walk toward the river.\n",
            "\n",
            "DECK PLAN\n",
            "\n",
            "1 Old Port\n",
            "\n",
            "2 Griffintown / Mile End\n",
            "\n",
            "3 Bonaventure Expressway\n",
            "\n",
            "4 Quartier Chinois\n",
            "\n",
            "SITE DE QUÉBEC INNOVATION\n",
            "\n",
            "The Site de Québec Innovation, formerly known as Quartier chinois, is the largest mixed-use, master-planned development in the world. It incorporates 2,600 rental units, nearly 740,000 square feet (69,000 square metres) of office space, 1.6 million square feet (150,000 square metres) of retail space, and the commercial headquarters of companies such as Samsung and Canadian Tire, along with the new National Assembly of Quebec. The development itself is 8.5 acres (3.5 hectares) and covers a wide area of the Old Port, extending from the east, toward the Old Port, and the west, across the Bonaventure Expressway to Place Philippe-Signal.\n",
            "\n",
            "RIVER AT THE SPOT\n",
            "\n",
            "The development's main attraction is an extensive riverside park. Its 30,000 square feet (2,822 square metres) are home to a lawn and outdoor sport facilities, including tennis and basketball\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 1024 this should take ~42.666666666666664 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m\n",
            "# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL\n",
            "## SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "The Old Port of Montreal is a\u001b[0m 12-kilometer-long waterfront, stretching from Gare Central to Île Notre-Dame. It's Montreal's oldest neighborhood, housing the city's most active nightlife and entertainment venues. In summer, it's the place to be: the city's _haute_ ville bustles with tourists and outdoor revelers. In winter, it's as close as you'll get to being out of town—a veritable Winter Wonderland.\n",
            "\n",
            "## FOREWORD\n",
            "\n",
            "_James Benett is a Montreal-based architecture firm with a longstanding focus on multifamily residential projects. This building forms the basis of their portfolio, and has been their bread and butter for decades. It's a residential community, a mix of one- and two-bedroom units, in a campus environment that—even though it has grown tremendously in size—is absolutely invigorating and unique, and architecturally sympathetic and respectful of its location._\n",
            "\n",
            "A long time ago in a universe far away, James Benett was invited to design the project for the new hockey arena for the Montreal Junior Canadiens. A bizarre series of events followed, where he met a stranger who was trying to figure out how to find him. Once found, he was somehow enlisted to design the poster announcing the new arena.\n",
            "\n",
            "This was supposed to be a quirky experience, the culmination of years of ruminating on the various approaches to architecture and design. James had a moment of clarity, of vision, that led him to a place where he would spend his professional career.\n",
            "\n",
            "Today, he has a client who has attracted a large following—a client who is undoubtedly fascinated by the way that _his_ ideas have a life of their own. The marketing people of this client are not averse to creating a series of posters with images derived from James's unclassified works.\n",
            "\n",
            "So much for the backstory. What about the building itself?\n",
            "\n",
            "The building, the _spaces cité multimédia,_ was built in 1997, and the concept behind it was born in the architectural firm's work for the aerospace industry. James and his team of young, enthusiastic designers were developing ideas for the space's new headquarters, and were frequently making trips to the deserts of California to gather inspiration and to observe the dynamics of living in the building's environment.\n",
            "\n",
            "One such design experiment in a shopping mall in Santa Cruz produced an image of a network of rooms linked by diagonal corridors, a design that was quite unlike anything in Montreal.\n",
            "\n",
            "During a trip to the shopping mall, James decided to sketch out a basic architectural model for a building of this type, a building that would contain the shopping mall in which he had recently been a guest.\n",
            "\n",
            "In the ensuing years, the building evolved through a series of design explorations, and came to reflect the origins of James's architectural career.\n",
            "\n",
            "Once the building was completed in 1997, it attracted a very large number of international tourists, and James Benett became a celebrity among local architects, many of whom had \"sneaked into\" the building in order to survey it, and had fallen in love.\n",
            "\n",
            "It was not always easy, being an architectural superstar. James once had an architect working for him in his office point out that he had started out as an architect, but by the time the project was completed, he had changed into something quite different. No doubt a few architects have done that in James's office.\n",
            "\n",
            "Some people (especially those who have known him for a long time) could talk about the building all night. They would talk about the huge core of public space, the open-door offices, the natural light, the spaces with four-sided views, and the bank of elevators (seven in all, for all the visitors), which have their own special identity as they zoom up and down the building.\n",
            "\n",
            "They would talk about the various pieces of furniture (from the bank of sofas and chairs, to the large collection of wooden sculptures), and they would talk about the building's wonderful control system, which allows so many things to happen, all on a very simple command: push or pull the various buttons.\n",
            "\n",
            "Most of the building's visitors think they will be impressed with its rich, sophisticated, and complex design. While it might be an impressive building, it's also, and more importantly, a very personal building. James designed it to be welcoming to a large number of people who might not even know that they were making a visit to an important personal residence.\n",
            "\n",
            "James Benett has succeeded in creating a building that has found many admirers, and it is almost as if the building was speaking to people on many different levels. To most people, the building says: \"Here, I am, and I've been made to speak, and I am enjoying it.\"\n",
            "\n",
            "Of course, no one could be a truer Montrealer than James Benett, and this building bears the mark of that fact. The concept of the building's roots in the\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 2048 this should take ~85.33333333333333 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m\n",
            "# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL\n",
            "## SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "The Old Port of Montreal is a\u001b[0m locus of cultural identity. With the decline of cultural industry in the twenty-first century, the need for cultural consumption is increasingly expressed through a seemingly unlimited range of activities and lifestyles. The construction of cultural and creative spaces has come to the fore. Among the many reasons for the revival of the Old Port and the creation of cultural spaces there are the increasing interest in more sustainable urban spaces and in “place making” in the various modes of urban culture, the development of creative industries, the opening of artists’ and designers’ studios, artistic and creative initiatives and other initiatives, and the commodification of cultural tourism. The Old Port of Montreal, the Quebec City Centre and the commercial centre of the Island of Montreal are hubs of the lifestyle activities of the urban classes of Montreal. In its character as a locus of economic and cultural activity, the Old Port is increasingly defined by its relationship to the Island of Montreal and its position as the functional urban space that connects the Island of Montreal to the Quebec City Centre.\n",
            "\n",
            "The population density of the Old Port of Montreal is one of the highest in the world. Although new developments take place in areas of the Old Port that are adjacent to residential areas, it is one of the most densely populated areas of the Island of Montreal. Among the various functions of the space that surround the Old Port, it should be stressed that the old quarters of the city function as a transition zone between areas of the Island of Montreal with a high population density and areas that have a low population density. Many functions are transacted here and, over time, this activity has developed into a major economic activity.<|endoftext|> up to do. They are like tiny specks of make-up you can't see, but it looks great, and its comfortable on your skin. The packaging is unique, too, and it isn't your standard thing where you take a nail file and you pull the corners of a plastic bag so that they can go in and you close them up, and you open them, and you close them up, and so on. Nope. This is something that opens up to show what's inside, and when you close it up, it looks neat like that. It really is that simple.\n",
            "\n",
            "You pull it out of the package and you pull off the top piece of plastic, you close it up, and you throw it in your bag.\n",
            "\n",
            "They are a good colour. The one I have is quite a soft pink, but it's a nice colour. It's a good colour for spring. It's spring in the UK. I know that sounds strange, but it's not spring, and it's not that I don't like spring. It's just that, because of the weather in England, it's raining almost every day. That's why I chose spring.\n",
            "\n",
            "It's very easy to use. You soak your nail files in the water, it comes out of the packet clean, and you've got nice clean cuticles, and your nail. And it works just as well for artificial nails as it does for natural. The only difference is that when you have a good manicure, or when you apply a good polish, the resin sort of stays on. And when you take a pair of scissors and you cut the nail in half, that resin sort of bubbles up out, but when you've got a good cuticle, it doesn't. So, its more difficult. If you have a good cuticle, you might need to use the brush, and you can press it down on your nail.\n",
            "\n",
            "It smells. The funny thing is, and this doesn't happen with every nail file, is that the first time I used this nail file, I didn't smell it. The next time, I still didn't smell it. The third time, I still didn't smell it. And the fourth time, I smelled it. I smelt it, and I was like \"what the...!\"\n",
            "\n",
            "That is something that happens with some nail files. When you first use them, you don't smell them. They don't smell, and then they start to smell. I know this doesn't sound like a nail file thing, but it is! When you are drinking your morning coffee or your afternoon tea, the same thing happens. It doesn't smell when you're drinking your morning coffee, and then it starts to smell when you get to the afternoon.\n",
            "\n",
            "It's not as sharp as it used to be. I'm afraid I'm going to have to agree with Mrs Kitten. I tried that, but there's no way. The nail file I have now is much sharper. I went to the store to buy a pack of these and the girl told me, in a very positive way, \"No no no! You need to get this pack because you will never go back to what you've got! This is the sharpest you will ever use, and it will last you a lifetime! Buy this, because you will never go back to the other nail file!\" And she was right, I can tell you!\n",
            "\n",
            "What's not to like? The only thing is that if you have a broken nail, I'd say you can't do that nail file technique because it's not good for the nail, and it can do damage to the nail. But other than that, its great, and you'd really be surprised at how much you can do in a day with this nail file. You can get a whole new look in a day, and when you're travelling, I know I always like to travel with some of my nail products. It's a hassle travelling with nails in a bag or with a nail file in a bag, but at least I've got something.\n",
            "\n",
            "This nail file is really nice. I don't think there's anything else like it. It's simple, it's easy to use, and it's great for getting rid of knots and for getting the rid of the nastiest part of your nail, and it doesn't hurt at all.\n",
            "\n",
            "Disclaimer\n",
            "\n",
            "I am not a medical practitioner, and the comments I make on this site are based on my own personal experiences. Please consult your doctor before beginning any new program of exercise or exercise technique.\n",
            "\n",
            "Also, the information provided on this site is not a replacement for medical advice. If you think you're ill, you should seek qualified medical advice from your doctor or health care practitioner.<|endoftext|>Doxfordia bicolor\n",
            "\n",
            "Doxfordia bicolor is a moth of the family Noctuidae. It is found from southern Great Britain, Ireland, Europe through north central Asia to Siberia. The habitat consists of old-growth forests, mainly on acid soils.\n",
            "\n",
            "Technical description and variation\n",
            "\n",
            "The wingspan is 26–35 mm. Forewing pale ochreous or ochreous whitish, with pale ochreous, blotchy markings; lines black; the median area bordered at base by a bright brown streak; an indistinct waved, submarginal line with a brown terminal line; hindwing pale grey. — ab. alpinus Guen. is larger and darker and has a broader dark streak along the terminal edge of the median area; -nigricans Boisduval is very similar, but the submarginal line is straight and the hindwing white; -ochraria Guen. is even darker, the markings are whitish, and the median area is greyer; -chionitis Grote is without the submarginal line, has a paler median area, and the hindwing whitish; ab. colorata Laicharting has the upper lobe of the forewing more pale ochreous than greyish ochreous, and the upper edge of the terminal line whitish. -nigricans Grote has the forewing brighter ochreous than pale ochreous; -morestria Grote has the markings darker, and the ochreous colour more brownish. — ab. canteri Grote, is a very bright tawny ochreous moth, with the markings more distinct and darker; the markings are somewhat sprinkled, but the pale streaks on the forewing are unusually broad and indistinct; — nigricans Grote is much brighter ochreous, with the markings darker; ab. rufipes Grote has the hindwing dusted with blackish, in addition to the pale ground colour.\n",
            "\n",
            "Biology\n",
            "The moth flies from June to August depending on the location.\n",
            "\n",
            "Larva can be found from July to September.\n",
            "\n",
            "The larvae feed on the leaves of alder and birch.\n",
            "\n",
            "References\n",
            "\n",
            "External links\n",
            "\n",
            " Taxonomy\n",
            "Lepiforum\n",
            "Hepialidae\n",
            "Fauna Europaea\n",
            "\n",
            "Category:Apameini\n",
            "Category:Moths of Europe\n",
            "Category:Insects of Europe\n",
            "Category:Insects of Turkey\n",
            "Category:Moths of Asia<|endoftext|> they need.\" \"There's a huge medical wing.\" \"It's got to be where we get cured.\" \"That's it!\" \"We'll hold them off here, you guys get in that med wing.\" \"Oh, right.\" \"This way.\" \"Somebody's gotta stay and hold off those guys.\" \"Come on, guys, let's get up to the med wing.\" \"Let's go, time to burn some fuel.\" \"Sweet mother of pearl!\" \"What happened?\" \"My force field...\" \"When they die, the control circuit shorts out and the force field goes off line.\" \"Ralph, are you OK?\" \"My lasers?\" \"I must recharge them.\" \"Hang on, Ralph.\" \"Everybody, grab hold.\" \"We'll bring you back to life.\" \"I can't hold on much longer.\" \"Your brother has a force field.\" \"Don't you ever bring him up again.\" \"He's got nothing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO89-sKMrucR"
      },
      "source": [
        "# Example prompts\n",
        "\n",
        "We've compiled the model. At this point it should only take about 15 seconds per sample. The first time you run inference on a new dataset takes longer than usual because of compilation to build the graph and write data into disk buffers for fast access by CPUs/GPUs.\n",
        "\n",
        "The following parameters can be adjusted: top_p, temp, gen_len. When changing the length of generations (gen_len), recompilation is required to maintain accuracy and consistency in results.\n",
        "\n",
        "You can also change other things like the number of generations done in parallel and how many samples are generated. In addition, you can increase or decrease the batch size for latency/throughput tradeoffs as well. This is useful when performing best-of-n cherry picking tasks where throughput needs to be maximized with minimum batch time delay on each sample generation process.\n",
        "\n",
        "To get the best results, make sure your prompt does not have any trailing spaces. This is because BPE tokenization can be confused by them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ViSfFkOUbS"
      },
      "source": [
        "## Simple Inference "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EStwU8WqXnBD"
      },
      "source": [
        "### Set Sampling Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akM-tZFTXnBE",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "876e77eb-a92f-439b-c2f6-a62d64317b9a"
      },
      "source": [
        "#@markdown ### Leave this alone unless you know what you are doing! \n",
        "#@markdown ... or you are just having fun experimenting and don't mind having weird results.\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
        "#@markdown Top_p controls diversity/quality. The higher our top_p the more rich and nuanced oir inferences can be.\n",
        "top_p = 1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Temp controls randomnes. Low temps make for mechanical inferences.\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Gen_len adjects the length of text infered.\n",
        "#@markdown Specifcily it adustes the nember of tokens (~4 per engish word).\n",
        "#@markdown\n",
        "#@markdown *Note: Changing gen_len will cause long wait times when first setting lengs that have not been set before.*\n",
        "#@markdown  \n",
        "gen_len = 192 #@param {type: \"slider\", min:64, max: 1024, step: 64}\n",
        "#@markdown - - - \n",
        "#@markdown Generate controls the number of inferences that will be generated.\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wUL-ryfYueS"
      },
      "source": [
        "### Text examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvlAK6RbCJYg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "aeebbc0a-9a80-474a-d6bd-50df55285abe"
      },
      "source": [
        "#@title Raw Context \n",
        "#@markdown This is an example of simple summery infrence.\n",
        "\n",
        "#print(\"Enter/Paste your content. Ctrl-D or Ctrl-Z ( windows ) to save it.\")\n",
        "#context = []\n",
        "#while True:\n",
        "#    try:\n",
        "#        line = input()\n",
        "#    except EOFError:\n",
        "#        break\n",
        "#    context.append(line)\n",
        "\n",
        "context = \"\"\"\"Some analysts expect bitcoin to eventually catch up to the rise in altcoins next week, which could push BTC’s price past $64,000 resistance.\n",
        "\n",
        "“Historically, there has been a slightly delayed positive correlation with traditional markets and the crypto market, helping to build the case for a bullish November for digital assets,” Will Morris, a trader at the U.K.-based digital asset broker GlobalBlock, wrote in an email to CoinDesk.\n",
        "\n",
        "Latest prices\n",
        "Bitcoin (BTC): 60,956.33, -0.30%\n",
        "Ether (ETH): 4,484.81, -0.01%\n",
        "S&P 500: 4,697.53, +0.37%\n",
        "Gold: 1,817.17, +1.44%\n",
        "10-year Treasury yield closed at 1.45%\n",
        "Traders will also be monitoring Coinbase’s (NASDAQ: COIN) third-quarter earnings report on Nov. 9. The crypto exchange delivered a negative earnings surprise in the second quarter because of declining trading volume. The cryptocurrency exchange’s shares are up about 40% over the past month compared to a 10% rise in bitcoin and a 25% rise in ether over the same period.\n",
        "\n",
        "\n",
        "Altcoin roundup\n",
        "Bitcoin cash briefly spikes on fraudulent press release: Bitcoin cash (BCH) rose a sharp 4.6% to $630.70 in under 15 minutes on Friday after a fraudulent press release went public, CoinDesk’s Jamie Crawley reported. The release stated that U.S. supermarket giant Kroger would start accepting the cryptocurrency as a form of payment during the year-end holiday season this year. However, the news – which was issued on PR Newswire and appeared on Kroger’s website – was quickly taken down after a spokesperson confirmed that it was fake news. The BCH price declined again and stood at $601.74 at press time.\n",
        "Argo blockchain shares fall after workers share non-public information: Shares of London-based crypto miner Argo Blockchain (ARBK) fell as much as 5% on Friday after the company said in a filing that some employees had inadvertently disclosed potentially material, non-public information in a conversation, CoinDesk’s Aoyon Ashraf reported. The discussion contained information about the potential increase in the company’s hashrate, or computing power, and the expected cost to build its planned facility in Texas, according to the filing. Argo listed its American depositary shares on Nasdaq in September; they are up roughly 3% since the listing.\n",
        "FTX, Lightspeed, Solana Ventures to invest $100 million in Web 3 gaming: FTX, Lightspeed and Solana Ventures are investing $100 million in Web 3 gaming development, CoinDesk’s Eli Tan reported. The funding will go towards the development of new titles as well as help with the integration of Solana’s blockchain into existing games, creating in-game economies centered around non-fungible tokens (NFT) and Solana wallet payments. The initiative has already made a first investment, with FTX and Lightspeed leading a $21 million funding round for gaming studio Faraway.\n",
        "\n",
        "Summary: BTC is\"\"\"\n",
        "\n",
        "inference = infer(top_p=top_p, temp=0.96, gen_len=128, context=context)[0]\n",
        "\n",
        "print(inference.split(\"Summary:\")[-1].strip())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BTC is\u001b[0m up around 2% on the day to $6,156 according to Bitfinex data. Earlier today, its top exchange – Bitfinex – said that while it stood by its comments that national banks and cryptocurrency platforms are going to cooperate with the cryptocurrency industry in the future, in light of the European Union’s new regulation and how it will impact bitcoin transactions, it’s seeing a drop in liquidity for bitcoin-enabled payment methods. Japan’s NBK is also planning to enforce rules on cryptocurrencies to protect customers, and the 30 yen-per-bitcoin levy demanded by South Korea’s main bank is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2omRWxDivro",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "547482a8-449f-42da-f8e3-feeb6b53ffc7"
      },
      "source": [
        "#@title Expand into a script \n",
        "#@markdown The will expand a lead into a script bassed on the opening of pulp fiction.\n",
        "write_script_on_this = \"Feline biology is amazing\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "#@markdown These options don't need to be adjusted.\n",
        "top_p = 0.9 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 512 #@param {type: \"slider\", min:64, max: 2048, step: 64}\n",
        "generate = 1 #@ param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "\n",
        "\n",
        "context = \"\"\"\n",
        "\n",
        "INT. COMPUTER LAB – MORNING\n",
        "\n",
        "A normal computer lab, an office or university, Toronto Canada.\n",
        "It's about 9:00 in the morning. While the place isn't jammed,\n",
        "there's a healthy number of people working, drinking coffee, \n",
        "reading at their computers.\n",
        "\n",
        "Two of these people are a YOUNG MAN and a YOUNG WOMAN. The\n",
        "Young Man has a slight working-class English accent.\n",
        "\n",
        "             YOUNG MAN\n",
        "  I want to tell you about what we've been studying.\n",
        "\n",
        "             YOUNG WOMAN\n",
        "  Oh? What have you been focusing on? \n",
        "\n",
        "             YOUNG MAN\n",
        "  {expand_this}. For example\"\"\"\n",
        "\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=context.format(expand_this = expand_this))[0])\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN8f4mvA97nG",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c1d3f621-724d-46ef-d4e2-3d5b38b6e8ef"
      },
      "source": [
        "#@title Make a title sound more academic \n",
        "#@markdown  \n",
        "improve_this = \"we're going ti make an instrument using the potentiometer \" #@param {type:\"string\"}\n",
        "#@markdown - - -\n",
        "top_p = 0.9 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 64 #@ param {type: \"slider\", min:64, max: 2048, step: 64}\n",
        "generate = 12 # @ param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = \"\"\"\n",
        "Instead of saying, \"{improve_this}\" a better shibboleth would be, \\\"\"\"\"\n",
        "\n",
        "#Indie Hackers want to click on titles such as \n",
        "#use something with more punch\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=context.format(improve_this = improve_this))[0].split('\"')[3])\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mwe're going to _make_ an instrument using the potentiometer\n",
            "\u001b[0mit will be our first instrument\n",
            "\u001b[0mwe're going to make an instrument that uses an active potentiometer\n",
            "\u001b[0mwe're going to measure the diameter of the potentiometer \n",
            "\u001b[0mit's going to be a binaural instrument\n",
            "\u001b[0mwe're going to modulate\n",
            "\u001b[0mwe're going ti make an instrument that changes in relation to the potentiometer.\n",
            "\u001b[0mwe're going to play a song\n",
            "\u001b[0mWe are going to design an instrument to control a potentiometer\n",
            "\u001b[0mwe're going to make a... instrument using the potentiometer\n",
            "\u001b[0mwe're going to create an instrument that takes advantage of the natural abilities of the potentiometer.\n",
            "\u001b[0mwe're going to make an electronic instrument based on this thing called a potentiometer \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrfIoe5BFaNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18bc1967-565c-467b-8b43-5c8e003050d9"
      },
      "source": [
        "str_list = [None, '', 0, \"Hi\", ' ', \"Hello\"]\n",
        "[x for x in str_list if x != '']\n",
        "[None, 0, \"Hi\", \"Hello\"]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 'Hi', 'Hello']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf63EvRmipH2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9464b00b-3c1c-4dbe-bb71-040193545da3"
      },
      "source": [
        "#@title Give headlines some more Clickbait \n",
        "improve_this = \"Make an instrument using the a light sensor \" #@param {type:\"string\"}\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - \n",
        "top_p = 0.9 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 1 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 64 # @ param {type: \"slider\", min:64, max: 2048, step: 64}\n",
        "generate = 5 #@ param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = f\"\"\"\n",
        "You need to make your title more clickbate. So instead of,\n",
        "\"{improve_this}\" use something with more punch such as,\\\"\"\"\"\n",
        "\n",
        "import codecs\n",
        "\n",
        "def yield_quoted_text(top_p=top_p, \n",
        "                       temp=temp, \n",
        "                       gen_len=gen_len, \n",
        "                       context=context):\n",
        "  while True:\n",
        "    inference = infer(top_p=top_p, \n",
        "                       temp=temp, \n",
        "                       gen_len=gen_len, \n",
        "                       context=context)[0].split('\"')[3].strip()\n",
        "    inference = repr(inference).split('\\\\x1b[0m')\n",
        "    inference = inference[1]\n",
        "    if inference !=\"'\":\n",
        "      yield inference\n",
        "\n",
        "#for x in range(generate):\n",
        "#    while not got_a_headline:\n",
        "for x in range(generate):\n",
        "  headline = next(yield_quoted_text())\n",
        "  print(headline)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How to Make an Arduino Controlled Instrument from a Camera'\n",
            "\\n\\nLight sensor\\n\\nBulb\\n\\nA possible sensor-light-controller\\n\\nPlaying a light bulb\\n\\nNot being another Linked Coffe Beans entry,\\nplease have a look at our post that we made earlier, which contains some\\nother awesome results.<|endoftext|>The present invention relates to a process'\n",
            "\\nHow to build a physics platformer using just a light sensor'\n",
            " How to Make a Light Sensor based Transparent Light Sensor'\n",
            "\\nCreate a Programmable LED Light using Arduino's LIGHT SENSOR\\nHow to Create a Remote Controller for Arduino, USB or Bluetooth\\nYou have an interesting idea, but that kind of coverage gets tiresome. As a result you just aren't going to draw many viewers. If I was looking for a\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCjGKMEJlDjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "527d2751-26ec-4cc5-ed05-95f1204c40a9"
      },
      "source": [
        "# @ title Generating inference prompts using tracery\n",
        "import tracery\n",
        "from tracery.modifiers import base_english\n",
        "\n",
        "rules = {\n",
        "    \n",
        "    'origin': 'It was a #type_of_day# #time# in #location# and',\n",
        "    'time': ['night', 'day', 'week', 'year'],\n",
        "    'type_of_day': ['amazing', 'spectaculare' , 'horid', 'spooky' ],\n",
        "    'location': ['Montreal', 'the woods', 'my head']\n",
        "}\n",
        "\n",
        "grammar = tracery.Grammar(rules)\n",
        "grammar.add_modifiers(base_english)\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=grammar.flatten(\"#origin#\"))[0] + \"\\n\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mIt was a spectaculare night in Montreal and\u001b[0m the ball was booming as the series between the Boston Red Sox and the Montreal Canadians in the 1956 World Series got started.\n",
            "\n",
            "At one point in the game, Norm Sherry -- the Boston Red Sox' first baseman -- takes off his helmet and, when he returns, it's with a new, bright pink one\n",
            "\n",
            "\u001b[1mIt was a spectaculare year in Montreal and\u001b[0m I remember it well. I felt at the time that Montreal really had something different, almost a uniqueness to it's feel and vibe, one that other cities may never be able to match in terms of that kind of atmosphere. It was truly unlike any other city I'd been in up to that point. I was not\n",
            "\n",
            "\u001b[1mIt was a spooky day in the woods and\u001b[0m it was all the Deputy's fault. It was just an ordinary day, until he was hosed down with live electric wire. The power surge almost blew his head off and put him on an alien spaceship. There were many magical creatures in the forest with advanced military training that were ready to defend their home planet. Will\n",
            "\n",
            "\u001b[1mIt was a amazing year in Montreal and\u001b[0m at the same time one of the most challenging one. I kept a pretty low profile last year in Montreal so that I could concentrate on the north and unfortunately the lack of results had a lot to do with my plate being overloaded. I missed my record of eight new bluepoint record last year. But this year’\n",
            "\n",
            "\u001b[1mIt was a spooky day in my head and\u001b[0m it kind of turned out spooky for everybody else too.”\n",
            "\n",
            "The result was the Giant Mountain Railroad, a circuitous little affair that carried its riders along a stretch of a map that any other would have taken a wrong turn to reach. The trail moves in and out of hilly terrain for most of\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvek96CyOnOh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "ba4bbb91-c498-4ba5-f0af-a7d2800a4845"
      },
      "source": [
        "# @ title Generating inference prompts using tracery\n",
        "import tracery\n",
        "from tracery.modifiers import base_english\n",
        "\n",
        "rules = {\n",
        "    \n",
        "    'origin': 'Our team builds #imagine# new online #location# beyond',\n",
        "    'imagine': ['amazing', 'spectaculare' , 'bold', ],\n",
        "    'location': ['worlds', 'spaces', 'colabortion']\n",
        "}\n",
        "\n",
        "grammar = tracery.Grammar(rules)\n",
        "grammar.add_modifiers(base_english)\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=grammar.flatten(\"#origin#\"))[0] + \"\\n\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mOur team builds amazing new online spaces beyond\u001b[0m the Internet where people create, connect, and collaborate in ways never before possible.\n",
            "\n",
            "At Poynter, we see that there is enormous value in the uncoordinated, noncommercial efforts of independent communities — the significance of citizen journalism, independent music stores, and unsanctioned Facebook pages, for instance\n",
            "\n",
            "\u001b[1mOur team builds bold new online worlds beyond\u001b[0m imagination. Whether you’re a Web developer or artist, we’re looking for you. Join us and help push the web forward.\n",
            "\n",
            "The Hermit that Brought You Cyberpunk…\n",
            "\n",
            "I will never forget my first experience with R. A. Salvatore’sThe Legend\n",
            "\n",
            "\u001b[1mOur team builds amazing new online worlds beyond\u001b[0m what has been done before, for every platform you can think of. For our latest technology projects we also use Unity, UnityWebEngine, Unreal, and more. For more information on the exact services our teams provide please click the links below. If you're interested in learning more about how you can use these services as\n",
            "\n",
            "\u001b[1mOur team builds spectaculare new online colabortion beyond\u001b[0m precancerous lesions screening programme (NPCR) in NIG, South Africa with all region of the country for cervical cancer screening of cancer by HPV testing. Using diagnostic accuracy study methods with 148 samples test results compared to colposcopy and histological results. The sensitivity of the results from our method was 90.\n",
            "\n",
            "\u001b[1mOur team builds bold new online worlds beyond\u001b[0m what anyone else can create. From interactive games, cinematic adventures, and original apps to virtual universes, our work is largely inspired by human stories, film, and philosophy. We work with artists, technologists, educators, academics, writers, psychologists, and games-makers from around the world to tackle challenges in web-\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5cJmv5ALxaM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "4ddf8601-16a1-4421-b873-25f6005a87ae"
      },
      "source": [
        "#@title Generating grading comment inference prompts using tracery\n",
        "import tracery\n",
        "from tracery.modifiers import base_english\n",
        "\n",
        "rules = {\n",
        "    \n",
        "    'origin': '#this_semester# Jane #does# #good_bad# in class. We hope that she',\n",
        "    'this_semester': ['Our focus this semester was learning to program microcomputers, using sensors, and building electronic circuits.','This semester we focused on learning to build electric circuits, reading information from sensors, and programming microcontrollers.'],\n",
        "    'does': ['works', 'does' , 'particpates', 'performs' ],\n",
        "    'good_bad': ['well', 'competently', 'baddly']\n",
        "}\n",
        "\n",
        "grammar = tracery.Grammar(rules)\n",
        "grammar.add_modifiers(base_english)\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=grammar.flatten(\"#origin#\"))[0] + \"\\n\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mThis semester we focused on learning to build electric circuits, reading information from sensors, and programming microcontrollers. Jane does competently in class. We hope that she\u001b[0m will continue this level of proficiency in a larger project and/or for a large portion of the term.\n",
            "\n",
            "September 2013\n",
            "\n",
            "Total amount due = $9,000\n",
            "\n",
            "January 2014\n",
            "\n",
            "This semester we focused on learning to build electric circuits, reading information from sensors, and programming microcontrollers. Jane\n",
            "\n",
            "\u001b[1mThis semester we focused on learning to build electric circuits, reading information from sensors, and programming microcontrollers. Jane particpates competently in class. We hope that she\u001b[0m will pursue science at a higher level, so she will consider STEM options, possibly in computer science or engineering. We have found that Jane has natural skills with mathematics, as she has an interest in geometry, making 3-d objects, and mathemetics, but has a real struggle when it comes to preperation\n",
            "\n",
            "\u001b[1mOur focus this semester was learning to program microcomputers, using sensors, and building electronic circuits. Jane performs competently in class. We hope that she\u001b[0m becomes better and better every day. A typical Saturday was spent with her doing programming, electronics, and robots. It's very exciting. She really likes her robot. We were out for the entire Saturday, and she was okay with that. The Saturday she came to school late, she was very sick. We were told\n",
            "\n",
            "\u001b[1mThis semester we focused on learning to build electric circuits, reading information from sensors, and programming microcontrollers. Jane particpates well in class. We hope that she\u001b[0m will enjoy pursuing electrical engineering as a profession.\n",
            "\n",
            "The kids are reading and playing when suddenly they are in the middle of a fire fight. A school bus is pulling up and the kids scramble to jump on. They get on and some are in trouble, another side rides away, and a few jump on other side\n",
            "\n",
            "\u001b[1mOur focus this semester was learning to program microcomputers, using sensors, and building electronic circuits. Jane particpates competently in class. We hope that she\u001b[0m will be able to continue with classes next semester when we plan to expand the Microsystm in this course to a Sensor system, including using GPS to provide distance information.\n",
            "\n",
            "Mar 12, 2009\n",
            "\n",
            "Installed a mechanical key switch into our system of the Hike and Make.\n",
            "This would control the\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c9FzqkVcZyZ",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "849d99c4-2c2e-4b60-eb59-de022ed4d3d7"
      },
      "source": [
        "#@title Article Generator \n",
        "title = \"STEAM Education\" #@param {type:\"string\"}\n",
        "site = \"https://www.media.mit.edu/\" #@param {type:\"string\"}\n",
        "date = \"\" #@param {type:\"string\"}\n",
        "author = \"Alexander Somma\" #@param {type:\"string\"}\n",
        "tags = \"#education #learning #school #motivation #love #students\" #@param {type:\"string\"}\n",
        "lead = \"## CHAPTER  2  The Growing Challenge\" #@param {type:\"string\"}\n",
        "#@markdown - - -\n",
        "generate = 1\n",
        "\n",
        "context = \"\"\"\n",
        "# {title}\n",
        "### Published:{date}\n",
        "### By:{author}\n",
        "##### Tags: {tags}\n",
        "### Site: {site}\n",
        "\n",
        "{lead}\n",
        "\"\"\"\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, \n",
        "              temp=temp, \n",
        "              gen_len=gen_len, \n",
        "              context=context.format(title =title, \n",
        "                                     site = site, \n",
        "                                     date = date, \n",
        "                                     author = author, \n",
        "                                     tags = tags, \n",
        "                                     lead = lead))[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "# STEAM Education\n",
            "### Published:\n",
            "### By:Alexander Somma\n",
            "##### Tags: #education #learning #school #motivation #love #students\n",
            "### Site: https://www.media.mit.edu/\n",
            "\n",
            "## CHAPTER  2  The Growing Challenge\n",
            "\u001b[0m---------------------------------\n",
            "\n",
            "\"*We are good at doing what we know how to do. We are very good at mess,\n",
            "and we are very bad at learning how to do new things.* - G. Sastry\n",
            "\n",
            "The quest we are currently on to understand the brain has not finished. A\n",
            "close look at the datasets available to us is revealing that there are\n",
            "fundamental driving forces behind our brains at work that we still do not\n",
            "comprehend. A traditional view on the brain is a collection of sensors and\n",
            "filters that are reacting based on what they are trained to react to, but\n",
            "there may be a wider role for the brain in how we learn.*\n",
            "\n",
            "Education is more than knowledge, it is a tool to unleash your creativity\n",
            "and imagination. The moments where you constantly dive into a subject to\n",
            "find the answer are the moments where your creativity is ignited. Education\n",
            "is the processor of feelings. We\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "nKpUf-M554f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dc231635-c282-4692-f8ee-08a948178d8f"
      },
      "source": [
        "#@title Article generation { form-width: \"300px\" }\n",
        "title = \"COVID-19: What do vaccine passports in Quebec & Ontario mean for Canada's largest provinces? \" #@param {type:\"string\"}\n",
        "site = \"https://www.canada.ca/en/public-health/services/diseases/\" #@param {type:\"string\"}\n",
        "date = \"Sep 7, 2021\" #@param {type:\"string\"}\n",
        "author = \"\" #@param {type:\"string\"}\n",
        "tags = \"COVID-19, Quebec, Ontario, Canada\" #@param {type:\"string\"}\n",
        "lead = \"The passports are certificates that confirm vaccinations and allow people to enjoy eating\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#print(\"Enter/Paste your content. Ctrl-D or Ctrl-Z ( windows ) to save it.\")\n",
        "#context = []\n",
        "#while True:\n",
        "#    try:\n",
        "#        line = input()\n",
        "#    except EOFError:\n",
        "#        break\n",
        "#    context.append(line)\n",
        "\n",
        "context = \"\"\"\n",
        "# {title}\n",
        "### Published:{date}\n",
        "### By:{author}\n",
        "##### Tags: {tags}\n",
        "### Site: {site}\n",
        "\n",
        "{lead}\"\"\"\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, \n",
        "              temp=temp, \n",
        "              gen_len=gen_len, \n",
        "              context=context.format(title =title, \n",
        "                                     site = site, \n",
        "                                     date = date, \n",
        "                                     author = author, \n",
        "                                     tags = tags, \n",
        "                                     lead = lead))[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "# COVID-19: What do vaccine passports in Quebec & Ontario mean for Canada's largest provinces? \n",
            "### Published:Sep 7, 2021\n",
            "### By:\n",
            "##### Tags: COVID-19, Quebec, Ontario, Canada\n",
            "### Site: https://www.canada.ca/en/public-health/services/diseases/\n",
            "\n",
            "The passports are certificates that confirm vaccinations and allow people to enjoy eating\u001b[0m in restaurants and buy alcohol.\n",
            "Those opposed to the measures say they will not work and are only for show.\n",
            "If we don't pass measures to limit the spread of COVID-19, the province would become one big flu season.\n",
            "At the moment, five people are confirmed to have COVID-19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka8vrZ-kN1Qi"
      },
      "source": [
        "## Code Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiXYadumWbT9"
      },
      "source": [
        "### Set Sampling Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSKHAVCYPt2W",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e3733f68-5ce9-4af6-abfd-831ffa456697"
      },
      "source": [
        "#@markdown ### Leave this alone unless you know what you are doing ... or are just having fun experimenting.\n",
        "#@markdown \n",
        "#@markdown - - - \n",
        "#@markdown Top_p controls diversity/quality. The higher our top_p the more rich and nuanced oir inferences can be.\n",
        "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Temp controls randomnes. Low temps make for mechanical inferences.\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Gen_len adjects the length of text infered.\n",
        "#@markdown Specifcily it adustes the nember of tokens (~4 per engish word).\n",
        "#@markdown\n",
        "#@markdown *Note: Changing gen_len will cause long wait times when first setting lengs that have not been set before.*\n",
        "#@markdown  \n",
        "gen_len = 512 #@param {type: \"slider\", min:64, max: 1024, step: 64}\n",
        "#@markdown - - - \n",
        "#@markdown Generate controls the number of inferences that will be generated.\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIGNc1D7XBQ-"
      },
      "source": [
        "### Python Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "phNf7ZPj3I8U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "ac3570a4-3c92-4e4a-dd78-7d2c16eb83d2"
      },
      "source": [
        "#@title Python Code - Simple \n",
        "#@markdown Generate code by just writng a comment and a name for a fuction \n",
        "python_comment = \"check if a number is prime or not\" #@param {type:\"string\"}\n",
        "#variable_n_val = \"youtube_video_url\" #@param {type:\"string\"}\n",
        "function_name = \"p\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "context = \"\"\"# {python_comment}\n",
        "\n",
        "def is_\"\"\".format(python_comment = python_comment, \n",
        "           function_name = function_name)\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m# check if a number is prime or not\n",
            "\n",
            "def is_\u001b[0mprime(n):\n",
            "\n",
            "    if n<2:\n",
            "        return False\n",
            "    if n%2==0:\n",
            "        return False\n",
            "    for x in range(3, int(n**0.5)+1, 2):\n",
            "        if n%x==0:\n",
            "            return False\n",
            "    return True\n",
            "\n",
            "A:\n",
            "\n",
            "Use the Sieve of Eratosthenes, to iterate over all the numbers less than or equal to your number, sifting them out until your input, or until you find a multiple.\n",
            "See https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes for more information.\n",
            "def is_prime(n):\n",
            "    # Initialize the list of all the numbers\n",
            "    # less than n\n",
            "    numbers = [2]\n",
            "\n",
            "    # Check the list, keeping track of the number of prime numbers found so far\n",
            "    found = 0\n",
            "\n",
            "    # Loop through all the numbers less than or equal to the input\n",
            "    for x in range(3, int(n**0.5)+1, 2):\n",
            "        # If a number is already in the list of prime numbers, then skip it\n",
            "        if x in numbers:\n",
            "            continue\n",
            "        # Add the current number to the list of prime numbers, unless it is divisible by any number currently in the list\n",
            "        if x not in numbers:\n",
            "            numbers.append(x)\n",
            "\n",
            "        # Remove the current number from the list of prime numbers\n",
            "        numbers.remove(x)\n",
            "\n",
            "    # If we found a prime number\n",
            "    if found > 0:\n",
            "        # return True\n",
            "        return True\n",
            "    else:\n",
            "        # return False\n",
            "        return False\n",
            "\n",
            "The function is_prime('100') returns true.\n",
            "\n",
            "<|endoftext|>Q:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Gs97bc_DCNIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "9f415ad1-53b0-4d1a-9f7a-a670180bab82"
      },
      "source": [
        "#@title Python Code - Complex\n",
        "python_comment = \"detect security flaws \" #@param {type:\"string\"}\n",
        "variable_name =\"person_real_name\" #@param {type:\"string\"}\n",
        "variable_val = \"Isabelle Plante\" #@param {type:\"string\"}\n",
        "function_name = \"online_account_scan\" #@param {type:\"string\"}\n",
        "#@markdown - - -\n",
        "\n",
        "\n",
        "context = '''#!/usr/bin/env python3\n",
        "\n",
        "# {python_comment}\n",
        "\n",
        "{variable_name} = \"{variable_val}\"\n",
        "\n",
        "def {function_name}(n):\n",
        "  \"\"\"This'''.format(python_comment = python_comment,\n",
        "           variable_name = variable_name,\n",
        "           variable_val = variable_val,\n",
        "           function_name = function_name)\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m#!/usr/bin/env python3\n",
            "\n",
            "# detect security flaws \n",
            "\n",
            "person_real_name = \"Isabelle Plante\"\n",
            "\n",
            "def online_account_scan(n):\n",
            "  \"\"\"This\u001b[0m function will \n",
            "     - scrap the information in the online account\n",
            "     - format the data in the output and then send it to the API\"\"\"\n",
            "\n",
            "  # constant variables\n",
            "  url = \"https://colaiseo.com/api/v1/account/user/info\"\n",
            "  header = {\"X-Api-Key\": \"d8feceb13e4e1c17d7d15f72e4e45ece\"}\n",
            "  post_data = {\"username\": str(n),\n",
            "               \"password\": \"\"}\n",
            "\n",
            "  # logic statements\n",
            "  print(\"\\n+-\"*50)\n",
            "  print(\"[*] Checking for login info in the online account\")\n",
            "  print(\"[*] Online account to check:\" + str(n))\n",
            "  print(\"[*] Retrieving the login info\")\n",
            "  # if we can reach the page \n",
            "  if(requests.get(url, headers=header, params=post_data).status_code == 200):\n",
            "    print(\"[+] Can reach the page\")\n",
            "    # get the response\n",
            "    data = requests.get(url, headers=header, params=post_data).json()\n",
            "    print(\"[+] Got the data\")\n",
            "    print(\"[*] Comparing the information with the database\")\n",
            "    for i in data:\n",
            "      if i[\"user_real_name\"]!= \"\".join(n):\n",
            "        print(\"[+] The data are not matching\")\n",
            "        print(i)\n",
            "        # adding the data to the output file\n",
            "        f = open(\"./output.json\", \"w\")\n",
            "        f.write(json.dumps(i))\n",
            "        f.close()\n",
            "        print(\"[+] Added data to output file\")\n",
            "      else:\n",
            "        print(\"[+] The data are matching\")\n",
            "        print(\"[+] Sending the output to API\")\n",
            "     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2u9WMX9Q-lG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "553f90fb-7b36-4813-deaa-ea8cc4865bc9"
      },
      "source": [
        "#@title Vue Code - Simple { form-width: \"500px\" }\n",
        "comment = \"guest speakers\" #@param {type:\"string\"}\n",
        "#variable_n_val = \"youtube_video_url\" #@param {type:\"string\"}\n",
        "name = \"tab_1\" #@param {type:\"string\"}\n",
        "#@markdown - - - \n",
        "#@markdown Leave this alone unless you know ...\n",
        "top_p = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 512 #@param {type:\"slider\", min:64, max:1024, step:64}\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = \"\"\"\n",
        "<!-- Vue template for {comment} page -->\n",
        "<section>\n",
        "  <div id=\"app\" class=\"container\">\n",
        "    <div class=\"content\">\n",
        "      <div id=\"{name} \" class=\"\"\".format(comment = comment, \n",
        "           name = name)\n",
        "      \n",
        "print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "<!-- Vue template for guest speakers page -->\n",
            "<section>\n",
            "  <div id=\"app\" class=\"container\">\n",
            "    <div class=\"content\">\n",
            "      <div id=\"tab_1 \" class=\u001b[0m \"tab-pane active\">\n",
            "        <div class=\"panel panel-default\">\n",
            "          <div class=\"panel-body\">\n",
            "            <div id=\"tab_1 \" class= \"tab-pane active\">\n",
            "              <div class=\"panel panel-default\">\n",
            "                <div class=\"panel-body\">\n",
            "                  <p>\n",
            "                    <a href=\"#\" data-toggle=\"tab\" role=\"tab\" data-target=\"#basic_info\">Basic Info</a>\n",
            "                  </p>\n",
            "                  <div id=\"basic_info\" class=\"tab-pane active\">\n",
            "                    <div class=\"panel panel-default\">\n",
            "                      <div class=\"panel-body\">\n",
            "                        <p>\n",
            "                          <span class=\"glyphicon glyphicon-user\"></span> {{ name }}\n",
            "                        </p>\n",
            "                        <p>\n",
            "                          {{ email }}\n",
            "                        </p>\n",
            "                        <p>\n",
            "   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZruXX6EYejiF"
      },
      "source": [
        "### JSON Gen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb8SkRpDm0rP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "cellView": "form",
        "outputId": "44ad138d-f3d9-42b0-e30f-f191c1c9b37a"
      },
      "source": [
        "#@title Json Code - Simple { form-width: \"500px\" }\n",
        "title = \"upcoming conferences\" #@param {type:\"string\"}\n",
        "#variable_n_val = \"youtube_video_url\" #@param {type:\"string\"}\n",
        "name_1 = \"subtitle\" #@param {type:\"string\"}\n",
        "#@markdown - - - \n",
        "#@markdown Leave this alone, unless... you know ...\n",
        "top_p = 0.9 # @ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.98 # @ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 96 # @ param {type:\"slider\", min:64, max:1024, step:64}\n",
        "generate = 1 # @ param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = f\"\"\"{{\"{title}\": [\n",
        "  {{\"{name_1}\":\"\"\"\n",
        "\n",
        "inference = infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0]\n",
        "\n",
        "first_key  = ('{\"' + name_1)\n",
        "\n",
        "inference = (first_key.join((inference.split(first_key)[0:-1])))\n",
        "print(inference)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m{\"upcoming conferences\": [\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5KKmPmApfXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "c277db95-2e3a-4e26-d517-6e55ff3eae86"
      },
      "source": [
        "#@title Extend last infrence\n",
        "#@markdown If you are happy with the last infrence run this to extend it.\n",
        "extended_inference = infer(\n",
        "    top_p=0.9, \n",
        "    temp=1.2, \n",
        "    gen_len=512, \n",
        "    context=inference)[0]\n",
        "print(extended_inference)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[1m{\"upcoming conferences\": [\n",
            "  \u001b[0m      \"invitations/conference\",\n",
            "        \"invitations/external_invite\",\n",
            "        \"invitations/send\"\n",
            "    ],\"total_count\": 10,\"result_type\": \"list\",\n",
            "    \"current_page\": 1,\"per_page\": 1,\"max_id\": 42}}\n",
            "\n",
            "A:\n",
            "\n",
            "just call oc get review \"orgname\", where \"orgname\" is the name of your oc.\n",
            "And this code is not valid for security:\n",
            "<view-status code=\"i\" key=\"normal\"></view-status>\n",
            "\n",
            "do\n",
            "   <action type=\"search\"></action>\n",
            "   <action type=\"submit\" callback-id=\"enter.search\"></action>\n",
            "\n",
            "This is valid:\n",
            "<view-status code=\"i\" key=\"normal\"></view-status>\n",
            "\n",
            "<|endoftext|>SOD3 can protect lens epithelial cells from oxidative damage and dysfunction in vivo and in vitro.\n",
            "To investigate the potential of protecting the ocular lens against oxidative damage by transferring superoxide dismutase 3 (SOD3) into the lens. The experiment was divided into two groups, in which either recombinant human SOD3 (rhSOD3) or sterile saline was injected into the lens capsule of rats or cultured human lens epithelial (HLE) cells in vitro. When injected into the lens, purified rhSOD3 reduced the release of H2O2 by rat lens epithelial cells and preserved the reduced GSH and cell morphology. When co-cultured with 2.5 × 104 microg/mL rhSOD3 for 24 h, the human lens epithelial cells were more resistant to oxidative damage and induced apoptosis in the presence of exogenous H2O2. Transgenic mice expressing a HLE cell-targeted hSOD3 fusion gene were resistant to the oxidative damage from the H2O2 stress. The long-term stability of the lens is closely associated with oxidative stress. By expressing human SOD3 into the lens, transgenic mice showed good lens function in vitro and in vivo and with resistance to oxidative stress in vivo.<|endoftext|>9/11 (statue)\n",
            "\n",
            "9/11 is a 2002 bronze statue of a figure of a man running holding a child, created by the American sculptor and medalist Greg M. Lee, and installed at the North Pool at the Pennsylvania Convention\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xiwQxqCNdz9"
      },
      "source": [
        "# Examples of GPT genereated code.\n",
        "\n",
        "The following are examples of code generated in prior runs.\n",
        "\n",
        "Please paste interesting examples below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgb9xlP394_5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a9365926-4528-4e4d-8eee-b527aa491606"
      },
      "source": [
        "# check if a number is prime or not\n",
        "\n",
        "def is_prime(n):\n",
        "  \"\"\" \n",
        "  > returns true if n is a prime,\n",
        "  > false otherwise.\n",
        "  \"\"\"\n",
        "  for i in range(2, n):\n",
        "    if n % i == 0:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "print(is_prime(7))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKo_2bvagu2K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "77420a11-1c62-4165-feab-e0e3dc7a68ff"
      },
      "source": [
        "# Program to check if a number is prime or not\n",
        "\n",
        "num = 9\n",
        "\n",
        "# Program to check if a number is prime or not\n",
        "\n",
        "def is_prime(n):\n",
        "    while n > 1:\n",
        "        while n % 2 == 0:\n",
        "            return False\n",
        "        n = n / 2\n",
        "    return True\n",
        "\n",
        "print(\"This is an example of a function that works but is quite wrong!\")\n",
        "\n",
        "for i in range(2, 20):\n",
        "  print(f\"Is {i} prime? {is_prime(i)}\")\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is an example of a function that works but is quite wrong!\n",
            "Is 2 prime? False\n",
            "Is 3 prime? True\n",
            "Is 4 prime? False\n",
            "Is 5 prime? True\n",
            "Is 6 prime? False\n",
            "Is 7 prime? True\n",
            "Is 8 prime? False\n",
            "Is 9 prime? True\n",
            "Is 10 prime? False\n",
            "Is 11 prime? True\n",
            "Is 12 prime? False\n",
            "Is 13 prime? True\n",
            "Is 14 prime? False\n",
            "Is 15 prime? True\n",
            "Is 16 prime? False\n",
            "Is 17 prime? True\n",
            "Is 18 prime? False\n",
            "Is 19 prime? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOwWzOgflhW0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4459b113-7318-4b54-ec86-2a171af9c131"
      },
      "source": [
        "# check if a number is prime or not\n",
        "def is_prime(n):\n",
        "    for i in range(2, n):\n",
        "        if n % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "is_prime(9)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA5qvTVnS0q8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "72e42a24-6ddf-46c2-bc89-de2941d91a4a"
      },
      "source": [
        "!pip install grip"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grip\n",
            "  Downloading grip-4.5.2.tar.gz (145 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▎                             | 10 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 20 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 30 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 40 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 145 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from grip) (0.6.2)\n",
            "Requirement already satisfied: Flask>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from grip) (1.1.4)\n",
            "Requirement already satisfied: Markdown>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from grip) (3.3.4)\n",
            "Collecting path-and-address>=2.0.1\n",
            "  Downloading path-and-address-2.0.1.zip (6.5 kB)\n",
            "Requirement already satisfied: Pygments>=1.6 in /usr/local/lib/python3.7/dist-packages (from grip) (2.6.1)\n",
            "Requirement already satisfied: requests>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from grip) (2.25.1)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.10.1->grip) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.10.1->grip) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.10.1->grip) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.10.1->grip) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.10.1->grip) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from Markdown>=2.5.1->grip) (4.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.1->grip) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.1->grip) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.1->grip) (2021.10.8)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.1->grip) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->Markdown>=2.5.1->grip) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->Markdown>=2.5.1->grip) (3.7.4.3)\n",
            "Building wheels for collected packages: grip, path-and-address\n",
            "  Building wheel for grip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grip: filename=grip-4.5.2-py3-none-any.whl size=136367 sha256=9e527e947437aacc178b16c9d579bda10bdc0d9b37ca784de0d54fa602f6dc12\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/30/85/3e6f333b21d81da3ae09530c732912f8015db564f757a92d54\n",
            "  Building wheel for path-and-address (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for path-and-address: filename=path_and_address-2.0.1-py3-none-any.whl size=4070 sha256=807d92056f4d536c44082f0902206a2d5e55a640638ec86c3437c9bffffa31d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ca/51/f8e74824b3054356141ac2dea86cea46efc55c02898fe11527\n",
            "Successfully built grip path-and-address\n",
            "Installing collected packages: path-and-address, grip\n",
            "Successfully installed grip-4.5.2 path-and-address-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXng0F4dSi4i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5fd01a73-3cdd-47c8-d996-dd08b4e20bf9"
      },
      "source": [
        "!pip install grip\n",
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(8000)\"))\n",
        "!grip 8000"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: grip in /usr/local/lib/python3.7/dist-packages (4.5.2)\n",
            "Requirement already satisfied: docopt>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from grip) (0.6.2)\n",
            "Requirement already satisfied: Flask>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from grip) (1.1.4)\n",
            "Requirement already satisfied: path-and-address>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from grip) (2.0.1)\n",
            "Requirement already satisfied: Pygments>=1.6 in /usr/local/lib/python3.7/dist-packages (from grip) (2.6.1)\n",
            "Requirement already satisfied: Markdown>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from grip) (3.3.4)\n",
            "Requirement already satisfied: requests>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from grip) (2.25.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.10.1->grip) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.10.1->grip) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.10.1->grip) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.10.1->grip) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.10.1->grip) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from Markdown>=2.5.1->grip) (4.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.1->grip) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.1->grip) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.1->grip) (2021.10.8)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4.1->grip) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->Markdown>=2.5.1->grip) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->Markdown>=2.5.1->grip) (3.6.0)\n",
            "https://fqu4ygmyobl-496ff2e9c6d22116-8000-colab.googleusercontent.com/\n",
            "Error: No README found at .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shgf_1CZSkI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f4e73287-7024-4513-aae1-b787742b9f8c"
      },
      "source": [
        "!pip install flask"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (1.1.4)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask) (2.0.1)\n"
          ]
        }
      ]
    }
  ]
}