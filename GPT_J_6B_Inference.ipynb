{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "GPT-J-6B Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/opencoca/vidsum/blob/master/GPT_J_6B_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHIJVqHsh4An"
      },
      "source": [
        "# GPT-J-6B Inference \n",
        "\n",
        "This notebook explores how to work with the [GPT-J-6B model](https://github.com/kingoflolz/mesh-transformer-jax/#GPT-J-6B). See the link for more details about the model, including evaluation metrics and credits.\n",
        "\n",
        "Please note it takes ~10 minutes for this notebook to fully spin up. Sometimes you will runout of ram when attempting to setup the model. If this happens factory restart the runtime and try again. If it contines to happen ...\n",
        "\n",
        "Start this notebok by clicking `Runtime > Run all` or clicking `⌘/Ctrl+F9`. Use `⌘` on Mac and `Ctrl` on Windows and Linux. \n",
        "\n",
        "Keep an eye on this as it spins up. Google likes to make sure you are not a bot and will stop things if you ignore the \"I'm not a robot\" popup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CMw_dSQKfhT"
      },
      "source": [
        "## Prepare it to be used\n",
        "\n",
        "### Install Dependencies\n",
        "\n",
        "First we download the model and install some dependencies. This step takes at least 5 minutes (possibly longer depending on server load).\n",
        "\n",
        "!!! **Make sure you are using a TPU runtime!** !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "JdkgIa72_2FT"
      },
      "source": [
        "#@title Mount Google Drive and install libs to Google Drive\n",
        "#@markdown This speeds up launch immensely\n",
        "\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0,nb_path)\n",
        "\n",
        "pk_path = '/content/site-packages'\n",
        "os.makedirs('/content/drive/My Drive/Colab Notebooks/site-packages', exist_ok=True)\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks/site-packages', pk_path)\n",
        "sys.path.insert(0,pk_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT1XmBc7BHwI",
        "cellView": "form"
      },
      "source": [
        "#@title Install Tensorflow\n",
        "!pip install --target=$pk_path tensorflow==2.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7xAFw-LOYfe"
      },
      "source": [
        "#@title Install GPT-J-6B\n",
        "!apt install zstd\n",
        "\n",
        "# the \"slim\" version contain only bf16 weights and no optimizer parameters, which minimizes bandwidth and memory\n",
        "!time wget -c https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
        "\n",
        "!time tar -I zstd -xf step_383500_slim.tar.zstd\n",
        "\n",
        "!git clone https://github.com/kingoflolz/mesh-transformer-jax.git\n",
        "!pip install --target=$pk_path -r mesh-transformer-jax/requirements.txt\n",
        "\n",
        "# jax 0.2.12 is required due to a regression with xmap in 0.2.13\n",
        "!pip install --target=$pk_path mesh-transformer-jax/ jax==0.2.12\n",
        "!pip install --target=$pk_path optax transformers dm-haiku einops jax==0.2.12 ray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO1UXepF-0Uq"
      },
      "source": [
        "## Setup Model\n",
        "\n",
        "You may have to restart your runtime before this will work. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex0qJgaueZtJ"
      },
      "source": [
        "#@title Setup JAX for TPU use\n",
        "import os\n",
        "import requests \n",
        "from jax.config import config\n",
        "\n",
        "colab_tpu_addr = os.environ['COLAB_TPU_ADDR'].split(':')[0]\n",
        "url = f'http://{colab_tpu_addr}:8475/requestversion/tpu_driver0.1_dev20210607'\n",
        "print(url)\n",
        "requests.post(url)\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIgUVdFLe4A8"
      },
      "source": [
        "Sometimes the next step errors for some reason, just run it again ¯\\\\\\_(ツ)\\_/¯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A5IGYSaeze3"
      },
      "source": [
        "#@title Import libraries\n",
        "import time\n",
        "\n",
        "import jax\n",
        "from jax.experimental import maps\n",
        "import numpy as np\n",
        "import optax\n",
        "import transformers\n",
        "\n",
        "from mesh_transformer.checkpoint import read_ckpt\n",
        "from mesh_transformer.sampling import nucleaus_sample\n",
        "from mesh_transformer.transformer_shard import CausalTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAgKq-X2kmba",
        "cellView": "form"
      },
      "source": [
        "#@title Set Network Parameters \n",
        "params = {\n",
        "  \"layers\": 28,\n",
        "  \"d_model\": 4096,\n",
        "  \"n_heads\": 16,\n",
        "  \"n_vocab\": 50400,\n",
        "  \"norm\": \"layernorm\",\n",
        "  \"pe\": \"rotary\",\n",
        "  \"pe_rotary_dims\": 64,\n",
        "\n",
        "  \"seq\": 2048,\n",
        "  \"cores_per_replica\": 8,\n",
        "  \"per_replica_batch\": 1,\n",
        "}\n",
        "\n",
        "per_replica_batch = params[\"per_replica_batch\"]\n",
        "cores_per_replica = params[\"cores_per_replica\"]\n",
        "seq = params[\"seq\"]\n",
        "\n",
        "\n",
        "params[\"sampler\"] = nucleaus_sample\n",
        "\n",
        "# here we \"remove\" the optimizer parameters from the model (as we don't need them for inference)\n",
        "params[\"optimizer\"] = optax.scale(0)\n",
        "\n",
        "mesh_shape = (jax.device_count() // cores_per_replica, cores_per_replica)\n",
        "devices = np.array(jax.devices()).reshape(mesh_shape)\n",
        "\n",
        "maps.thread_resources.env = maps.ResourceEnv(maps.Mesh(devices, ('dp', 'mp')))\n",
        "\n",
        "tokenizer = transformers.GPT2TokenizerFast.from_pretrained('gpt2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "T7kJZTkVQ2CZ"
      },
      "source": [
        "#@title Install Tracery \n",
        "#@markdown Tracery is a gramar for spining articles, stories, and text in general. https://github.com/aparrish/pytracery\n",
        "!pip install tracery"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-xgsL0IFTZt0"
      },
      "source": [
        "#@title Tidy things up\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwNETD2Uk8nu",
        "cellView": "form"
      },
      "source": [
        "#@title Create the network\n",
        "#@markdown ...loading neural weights from the downloaded files. \n",
        "#@markdown\n",
        "#@markdown  > *This can take around 5 minutes.*\n",
        "total_batch = per_replica_batch * jax.device_count() // cores_per_replica\n",
        "\n",
        "network = CausalTransformer(params)\n",
        "\n",
        "network.state = read_ckpt(network.state, \"step_383500/\", devices.shape[1])\n",
        "\n",
        "network.state = network.move_xmap(network.state, np.zeros(cores_per_replica))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-eT7Sw6if4J"
      },
      "source": [
        "# Run Model\n",
        "\n",
        "Finally, we are ready to infer with the model! The first sample takes around a minute due to compilation, but after that it should only take about 10 seconds per sample.\n",
        "\n",
        "Feel free to mess with the different sampling parameters (top_p and temp), as well as the length of the generations (gen_len, causes a recompile when initially changed - recompiles will be cached).\n",
        "\n",
        "You can also change other things like per_replica_batch in the previous cells to change how many generations are done in parallel. A larger batch has higher latency but higher throughput when measured in tokens generated/s. This is useful for doing things like best-of-n cherry picking.\n",
        "\n",
        "*Tip for best results: Make sure your prompt does not have any trailing spaces, which tend to confuse the model due to the BPE tokenization used during training.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuZq54dh8opl",
        "cellView": "form"
      },
      "source": [
        "#@markdown We allow for text wrapping of whitespace via css injection.\n",
        "\n",
        "# allow text wrapping in generated output: https://stackoverflow.com/a/61401455\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVzs2TYlvYeX",
        "cellView": "form"
      },
      "source": [
        "#@title Define our infer function. \n",
        "def infer(context, top_p=0.9, temp=1.0, gen_len=256):\n",
        "    tokens = tokenizer.encode(context)\n",
        "\n",
        "    provided_ctx = len(tokens)\n",
        "    pad_amount = seq - provided_ctx\n",
        "\n",
        "    padded_tokens = np.pad(tokens, ((pad_amount, 0),)).astype(np.uint32)\n",
        "    batched_tokens = np.array([padded_tokens] * total_batch)\n",
        "    length = np.ones(total_batch, dtype=np.uint32) * len(tokens)\n",
        "\n",
        "    start = time.time()\n",
        "    output = network.generate(batched_tokens, length, gen_len, {\"top_p\": np.ones(total_batch) * top_p, \"temp\": np.ones(total_batch) * temp})\n",
        "\n",
        "    samples = []\n",
        "    decoded_tokens = output[1][0]\n",
        "\n",
        "    for o in decoded_tokens[:, :, 0]:\n",
        "      samples.append(f\"\\033[1m{context}\\033[0m{tokenizer.decode(o)}\")\n",
        "\n",
        "    #print(f\"completion done in {time.time() - start:06}s\")\n",
        "    #this should instead be added to the object returned infered.samples and infered.completion_time\n",
        "    return samples\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rjWw1zkEOP8z",
        "outputId": "cb1ddf83-b88a-4171-e7d1-2fae011649e7"
      },
      "source": [
        "#@title Warmup our inference engine \n",
        "#@markdown The first time that infrences are run for a given length takes imensly longer than on repeated runs. For this reason we spin up the inference engine with a few sample runs. With this out of the way we can quickly experiment with our infrence engine. \n",
        "\n",
        "context = \"\"\"# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL AT SPACES CITÉ MULTIMÉDIA\n",
        "\n",
        "## The Old Port of Montreal is a\"\"\"\n",
        "\n",
        "for i in [32,64,96,128,256,512,1024,2048]:\n",
        "  print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
        "  print(f\" ## Infering context with a gen_len of {i} this should take ~ {i/32} sec. when run again ##\")\n",
        "  print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
        "  print(infer(context, gen_len=i)[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 32 this should take ~ 1.0 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL AT SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "## The Old Port of Montreal is a\u001b[0m piece of history\n",
            "\n",
            "The Old Port of Montreal is currently undergoing a revitalization project. However, its planning is about more than just presenting a new image.\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 64 this should take ~ 2.0 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL AT SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "## The Old Port of Montreal is a\u001b[0m Treasure Chest of \"Starving Artists\"\n",
            "\n",
            "The Old Port of Montreal (OPM), its theaters, cinemas, and galleries are bursting with creativity. In a city known for its engineering feats, the OPM has remained largely unchanged for many years, and as a result, has an artistically vibrant and lively\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 96 this should take ~ 3.0 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL AT SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "## The Old Port of Montreal is a\u001b[0m quiet, working neighborhood\n",
            "\n",
            "* * *\n",
            "\n",
            "**SALLIE R. CHATTIN**\n",
            "\n",
            "* * *\n",
            "\n",
            "**AT THE PENTAGON IN MONTREAL**\n",
            "\n",
            "After walking across Canada, I always take in the view of the Old Port from the Bonaventure Pier. I appreciate its charm as an architectural landmark as well as the view of the marina. At the Bonaventure, I usually choose a table along the\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 128 this should take ~ 4.0 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL AT SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "## The Old Port of Montreal is a\u001b[0m human-scale city. This is not a new idea. As a city, we've always considered ourselves human-scale. We embrace diversity and even our bays and rivers have names that reveal who we are. To our great pleasure, and mostly through our own efforts, the Old Port of Montreal has also been a \"theatrical space\" for decades. As playwrights, improvisers, performers, and community artists, we've shared and shaped this extraordinary area for decades through events that engaged a wide audience. For example, in 1980 we founded New Act Theatre Company, and its first theatrical performance took place in the old Ad\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 256 this should take ~ 8.0 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL AT SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "## The Old Port of Montreal is a\u001b[0m real example of a new type of use of a contemporary spatial environment. _Photo by the author_.\n",
            "\n",
            "I began my search in April 2004. I was traveling around France, looking for examples of contemporary small communities where the centre was made by the community and not the state or an entrepreneur. I was quite intrigued by what I read in the book _Bruegel the Elder: The World of Jan Bruegel_, edited by D. Elbourne and D. Robb, and took note of all the initiatives in Montréal, some of which are described in the introduction. When I arrived in the Old Port of Montréal, I was impressed by the playful attention given to the city and its place in society. What was my surprise to find a large university campus adjacent to the Old Port. The university, Université du Québec à Montréal (UQAM), was built in the mid-1980s to provide the campus for its graduate-degree programs. The buildings are right on the waterfront, but the plan was to have them progressively moved away from the river so that the campus could be gradually redesigned to link its student residential buildings to the waterfront. A striking part of the university campus is that it was developed to integrate the quays with\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 512 this should take ~ 16.0 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL AT SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "## The Old Port of Montreal is a\u001b[0m cultural gem which needs our support.\n",
            "\n",
            "When I was growing up, people used to talk about a very specific type of city. A city where the old is built on top of the new and where culture is interwoven with industry, where, in the words of Charles Dickens, culture is the flower of commerce, the taste of fashion and sound of trade. New York, Paris, London.\n",
            "\n",
            "People came here from all over the world to work in the industries of the new city, and, because of the wealth created, we became a destination for artists and musicians.\n",
            "\n",
            "That was the New York of my generation. What we created, in those magnificent golden decades, was the perfect balance between the capital and the capital of culture.\n",
            "\n",
            "But today things have changed. Not many people come here to work in the new businesses. Most of the new businesses are still in the West Island. And the musicians and the painters and the performers are mostly from the West Island. So for Montrealers the culture industry is mostly within our small geographical territory.\n",
            "\n",
            "We are drowning in culture.\n",
            "\n",
            "Our pride has become self-consciousness. Our intellectuality has become conceit. Our art is our misery. We are overly conscious of being Montrealers.\n",
            "\n",
            "It is this basic imbalance that is at the root of our current ills. The metropolitan society, defined by every culture in the world, has eroded to a certain point the kind of balanced urban society that gave birth to the modern world.\n",
            "\n",
            "Culture is the critical agent of our existence and yet it has been completely outsourced. Our means of production is going through a revolution. But our activities and our values have barely changed.\n",
            "\n",
            "We should be the hub of the world's knowledge and this hub needs to be based in a perfect balance between old and new, commerce and culture. It's time to rebuild the balance. It's time to re-create the bridge between the historic city centre and the West Island.\n",
            "\n",
            "This is the fundamental challenge of the Old Port.\n",
            "\n",
            "Where did this phenomenon of self-consciousness come from? Why can we no longer enjoy being Montrealers as we once did? Where is the balance?\n",
            "\n",
            "There is no time to answer that question here. We don't have the space. All I can do is provide a broad outline of the problem, with the hope that my colleagues and friends will take this out of my head and start working with it.\n",
            "\n",
            "A radical overhaul of the\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 1024 this should take ~ 32.0 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL AT SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "## The Old Port of Montreal is a\u001b[0m huge place to work, with lots of information and work stations to choose from. Photo: Spaces Cité Multimedia\n",
            "\n",
            "# INTRODUCTION\n",
            "\n",
            "IN THE OLD PORT OF MONTREAL (OPM) construction, port terminals, repair shops and facilities like the Champlain Bridge are scattered on a vast territory that extends from the Old Port across Rue Notre-Dame Est in the southeast to Rue De La Gauchetière Est in the west. This area encompasses numerous buildings, including five technical libraries (Arras Library, Library of the Institut de recherches historiques sur l'Amérique française (IRAH), Institut d'histoire de Montréal (IHMR), Montreal Public Library, and Société de musées canadiens du Québec (SMCQ)), six art museums (Concordia, Deschatelets, ICA, MUSIQUE, Royal, and SMCQ), the _Palais des Congrès_, and many other governmental institutions and cultural centers.\n",
            "\n",
            "The OPM also offers countless organizations with their own offices or business headquarters (including Métro, Conseil des ministres, BIA, Energir, OC Transpo, Hydrogène Québec, and Memso, to name a few). The Old Port's extensive commercial and industrial zones in the Port of Montreal—the West Island Port (WIP), the cargo terminal on Général-De Gaulle Island (CTG) and Pier 21, and the deep-water port of Montreal (DPM)—are also components of the OPM. In addition, the former site of the General Motors assembly plant (GM) on Rue Notre-Dame Est, in the southwest, is a major site.\n",
            "\n",
            "The OPM is bounded by various land uses, including university and college campuses, residential districts, open-space areas, industrial zones, the Lachine Canal, and the Lachine Museum. The largely accessible Port of Montreal, which is lined with handsome, two- to three-storey offices and small shops, now accommodates more than four million people per year. The area is also the site of more than 3,600 businesses with a combined annual turnover of $9.4 billion (2012) and over 30,000 residents. It generates $4.2 billion in income taxes, $1.5 billion in other taxes, and another $5.2 billion in social and economic benefits. All of these taxes are collected by the City of Montreal.\n",
            "\n",
            "# THE FIRST PORT\n",
            "\n",
            "In the mid-sixteenth century, a small harbour was constructed on an island within the Port of Montreal, near Notre-Dame Street (now Boulevard Saint-Jacques). Although the site remained that of a small harbour throughout the seventeenth and eighteenth centuries, the residents of the Old Port area could not pass through the water that separated the island and the mainland of Montreal. As a result, by the nineteenth century, the Old Port had expanded into an area that encompassed the island and parts of today's Old Port, Chinatown, Griffintown, and Parc-Extension. In this section, we explore some of the key monuments in the Old Port and discuss their history.\n",
            "\n",
            "**FOUNDATION OF THE OLD PORT**\n",
            "\n",
            "The very first settlement in Montreal was on the island, which was a subject of fierce conflict among the Iroquois. In the sixteenth century, the area was renamed and settled by the French. Port-Royal, located on a small island adjacent to the city's central area, was built in 1642.\n",
            "\n",
            "It was only during the era of the Great Migration that the community that became known as the Old Port developed. A group of French migrants, refugees from the British colonies and loyalists, settled in the area that we now call Old Montreal. The original settlers and early French Canadian bourgeoisie chose to live among the dense buildings of a compact urban district. As other French-Canadian migrants and working classes joined them, they further filled out the neighbourhood.\n",
            "\n",
            "When the first Port-Royal settlers first arrived in the 1640s, the Island of Montreal consisted of a wide expanse of grassy field, except for a small hill on which the chapel and the graveyard stood. The congregation gathered in the open during the service, as their religious observances were conducted out in the open. The church itself was generally in the centre of the churchyard, facing the mass grave that marked the place where the dead were laid to rest. The church and the cemetery became synonymous in Montreal.\n",
            "\n",
            "**A HERITAGE SITE WITH A HERITAGE**\n",
            "\n",
            "The word _château_, in French, literally means \"castle,\" and the _château-fort_ (\"fortified castle\") is the official title of a historic site that has been protected by law for a century.\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            " ## Infering context with a gen_len of 2048 this should take ~ 64.0 sec. when run again ##\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\u001b[1m# A NEW WAY TO WORK IN THE OLD PORT OF MONTREAL AT SPACES CITÉ MULTIMÉDIA\n",
            "\n",
            "## The Old Port of Montreal is a\u001b[0m spacious canvas for much-needed cultural diversification.\n",
            "\n",
            "**People & Places** _This edition marked the fifty-seventh anniversary of the Old Port of Montreal by inviting six writers to explore the monumental spectacle. Over the years, architects and urbanists have struggled with the mythic and romantic facets of this unique Canadian space. As architectural critic Christian Ialomińczyk asserts, the past fifty years have taught us a great deal about Montreal: for better and for worse. Today, many Montrealers can read the riot act to the naysayers. Modernist architecture has been equated to wealth, power and success. And yet, the re-emergence of the cultural, architectural and social scene at the Old Port is seen as a sign of the city's revitalization. Today the urban theatre in the Old Port is prospering, while downtown redevelopment marches on._\n",
            "\n",
            "_There is much in Montreal that needs renewal and the Old Port is no exception. Our Old Port_ ** _2_** _has become much more than just a place where the Royal Bank_ ** _3_** _has its headquarters. Since the twentieth century, the Bank of Montreal's austere presence has seemed set against the façade of three of the old Bank of Montreal banks. That façade represents the heart of Montreal. I contend that the Old Port of Montreal is a picture of the contradiction between the past and the future, an architectural and cultural comment on Canada._ ** _4_** _It must be said, of course, that the construction of the Bank of Montreal building was not done to the spirit of the original Bank of Montreal; that architectural decision represents nothing but modern-day political history. The financing came from a confederation of bankers who wished to shift the headquarters of their respective banks to the larger banks, so they came together to build a new bank in the city. But let's face it, a self-evident statement like this hardly does justice to the monumental vision of the bank. The opening of the Main Auditorium has been heralded as one of the greatest architectural feats in all of Canada._ ** _5_** _This bank, built on the site of two previous downtown banks, is one of Montreal's icons. Yet, the bank is hardly typical of the original vision of the architect, an artist, Henry Pinto and, for that matter, one of the founders of modern architecture in Montreal, Évariste Galle. \"This work was conceived with the scale and intention of making one whole,\" Pinto told French-Canadian architect and photographer Jacques Lacarrière in the late 1930s. \"It was a work that one will never see copied.\" Pinto claimed that this work was the unique solution to the problems of scale._ ** _6_** _This work of art should be considered much more than just a bank._ ** _7_** _And it should also be recognized for what it is – the ultimate statement of art as art._\n",
            "\n",
            "_In this short essay, I wanted to encourage readers to take a fresh look at the \"old port\" of Montreal. When I first moved to Montreal in the early 1990s, it seemed to me that the historic ambience of the area was being overshadowed by a parade of art galleries and clubs on Saint Catherine Street. In 1994, while making a documentary for the_ Hommage à Jules Poulin _show on Radio-Canada, I proposed an alternative to the \"experimental\" approach adopted by some of the galleries and cultural institutions in the area. The Old Port would serve as a multifaceted cultural centre, an open-air laboratory to revitalize the old Port._ ** _8_** _I still believe this to be the case._ ** _9_** _And so I present a bit of what I would consider to be a new way of working in the old port of Montreal._ ** _10_** _I also attempt to remind people that the Old Port has an enormous cultural value. The notion of cultural diversity is one of the keys to a renewal of the city._ ** _11_**\n",
            "\n",
            "**ARCHITECTURAL HERITAGE**\n",
            "\n",
            "**1**\n",
            "\n",
            "**OLD PORT OLD-FASHIONED ADVERTISING**\n",
            "\n",
            "EVERYTIME YOU walk along the water in the Old Port, you must admire the colourful, joyful and contagious advertising. Montreal is unique in Canada. It's true. It's a city that has retained its Old World character. It's even true. You still sometimes see advertisements in the streets that look like they came from the 1950s or '60s. And that's true too. In the Old Port, all of this mix of old and new is easy to observe. Even when we walk along Saint Catherine Street, we are bombarded by pictures and messages. We are rarely protected from the relentless flow of information and advertisements in the world around us. It's as if the stuff of life was always present, never interrupted. We are confronted with them on a daily basis. So there's no need for the city to play the role of the censors anymore. In the Old Port, people are free to roam and experience the visual message without the intervention of moralistic legislation. It's as if the city is reinventing itself again and we can watch. The truth is, this urban exhibition has become, over time, a little worn and dusty, so we have to come back and clean it up every once in a while.\n",
            "\n",
            "As architects and urbanists, we may be the purists, the bourgeoisie of the street, but we do believe in the power of the spoken word. And sometimes, we'd like to create spaces that will echo the word itself. Because if we can't do this, the spoken word is lost. So we like to suggest to visitors that they take the time to walk a little farther than what may seem to be a good idea on Saint Catherine Street. Take the time to wander among the numerous maritime businesses. Get out of the rush. Stop for a second. Imagine. You are facing the water and here, you can take in some aspects of what this unique Montreal landscape represents. The Seine, the water, the boats and the smells of the sea. There are still beautiful boats operating in the Montreal area. And here, you can see the whole gamut of maritime business that exists in the city. Look at the old-fashioned dockers' canteens. You will see people working in the sheds. You can still hear the pounding of the cranes, the din of the construction site. Then look at the fancy shops and the beautiful art galleries. They are there too. Here, you will find all of that mixed with this tremendous celebration of advertising. So let's walk a bit farther. Let's let the Old Port speak for itself.\n",
            "\n",
            "**NEW SPACES IN A SPACIOUS CANVAS**\n",
            "\n",
            "Today, it's easy to take the Old Port for granted. If you look carefully, you'll find many businesses here that are truly unique. There are docks where you can take an amphibious vehicle out onto the waves. There is a ship-building yard where large work vessels are built for offshore oil companies and the Montreal Steamship Company. There are a lot of businesses here that operate solely on the water. Take for example the fish and seafood restaurants. You will find restaurants that keep their fish alive in tanks, as if you were still back in the world of living, breathing animals. Then, there are the large boats that transport goods and employees around the city and for the Canadian and international market. Or there are the ships that operate cruises along the coast, where you can find a cozy atmosphere and a nice view of the scenery, complete with delicious gourmet dishes.\n",
            "\n",
            "All of these unique businesses in this unique Montreal canvas are the real muscle of our community. If it weren't for these maritime businesses, we wouldn't be here. This is the history of the city. And yet, there has always been a struggle, a resistance, to encourage Montrealers to take a new perspective on this environment. On the one hand, we are highly conscious of this urban image. It's even hard to do anything on Saint Catherine Street without considering how it might be interpreted. On the other hand, we sometimes fall prey to all sorts of de-urbanization. As public space and spaces that are meant to promote economic activity, the Old Port has become a space that many people prefer to ignore, to take for granted. We are going to prove them wrong. We want to offer our visitors the most \"horizonally\" oriented vision possible of this magnificent space.\n",
            "\n",
            "This is a place where we are building an urban laboratory. We are a collective of artists, designers, researchers, engineers, architects, city planners and ordinary residents. We want to continue the work of establishing the Old Port as a meeting space for all of Montreal. There are great artists, designers, architects and designers, photographers and painters, cultural entrepreneurs and ordinary Montrealers. We've set out to create an urban place that is open and inviting. Our aspiration is that the spaces of the Old Port will serve as an effective tool in the consolidation of this new social fabric of the city. But it won't be easy. The past fifty years have taught us a lot of things about the Old Port. Let's take a look at the most obvious truth. The Old Port is a magnet for businesspeople. It may be out of step with the climate of the moment. But in order for things to change, we have to be sure that the city provides itself with an attractive frame for business. That's a reality. Whether we like it or not, it's an important reality. When a large portion of our tourist community is employed at one of the sites built in the downtown area, the effect of positive and negative stimulation is significantly weaker. If, on the other hand, a large portion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO89-sKMrucR"
      },
      "source": [
        "# Example prompts\n",
        "\n",
        "We've compiled the model. At this point it should only take about 15 seconds per sample. The first time you run inference on a new dataset takes longer than usual because of compilation to build the graph and write data into disk buffers for fast access by CPUs/GPUs.\n",
        "\n",
        "The following parameters can be adjusted: top_p, temp, gen_len. When changing the length of generations (gen_len), recompilation is required to maintain accuracy and consistency in results.\n",
        "\n",
        "You can also change other things like the number of generations done in parallel and how many samples are generated. In addition, you can increase or decrease the batch size for latency/throughput tradeoffs as well. This is useful when performing best-of-n cherry picking tasks where throughput needs to be maximized with minimum batch time delay on each sample generation process.\n",
        "\n",
        "To get the best results, make sure your prompt does not have any trailing spaces. This is because BPE tokenization can be confused by them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ViSfFkOUbS"
      },
      "source": [
        "## Simple Inference "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EStwU8WqXnBD"
      },
      "source": [
        "### Set Sampling Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "akM-tZFTXnBE",
        "cellView": "form",
        "outputId": "05abc730-b764-4ab6-c421-43885ce4bf75"
      },
      "source": [
        "#@markdown ### Leave this alone unless you know what you are doing! \n",
        "#@markdown ... or you are just having fun experimenting and don't mind having weird results.\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
        "#@markdown Top_p controls diversity/quality. The higher our top_p the more rich and nuanced oir inferences can be.\n",
        "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Temp controls randomnes. Low temps make for mechanical inferences.\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Gen_len adjects the length of text infered.\n",
        "#@markdown Specifcily it adustes the nember of tokens (~4 per engish word).\n",
        "#@markdown\n",
        "#@markdown *Note: Changing gen_len will cause long wait times when first setting lengs that have not been set before.*\n",
        "#@markdown  \n",
        "gen_len = 64 #@param {type: \"slider\", min:64, max: 1024, step: 64}\n",
        "#@markdown - - - \n",
        "#@markdown Generate controls the number of inferences that will be generated.\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wUL-ryfYueS"
      },
      "source": [
        "### Text examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "nvlAK6RbCJYg",
        "cellView": "form",
        "outputId": "84e70f35-0ec3-4155-d745-a330a3f29e38"
      },
      "source": [
        "#@title Raw Context \n",
        "#@markdown This is an example of simple summery infrence.\n",
        "\n",
        "#print(\"Enter/Paste your content. Ctrl-D or Ctrl-Z ( windows ) to save it.\")\n",
        "#context = []\n",
        "#while True:\n",
        "#    try:\n",
        "#        line = input()\n",
        "#    except EOFError:\n",
        "#        break\n",
        "#    context.append(line)\n",
        "\n",
        "context = \"\"\"\"\n",
        "\n",
        "Article:\n",
        "\n",
        "t’s an intense crypto dogfight as dogecoin (DOGE) and shiba inu (SHIB), two of the most popular meme coins, battle it out for the ninth spot on the list of top digital assets by market capitalization. Some traders are profiting from the action by taking spread trades.\n",
        "\n",
        "DOGE has come alive after lagging SHIB by a significant margin earlier this month. The joke cryptocurrency surged to $0.335 on Coinbase on Thursday, hitting the highest level since Aug. 20. It was last trading near $0.30, representing a 22% gain on the day.\n",
        "\n",
        "Meanwhile, SHIB crashed as much as 30% to $0.00006 earlier today, having chalked out a rally to $0.00009 in the seven days to Oct. 27.\n",
        "\n",
        "Summery:\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=1, gen_len=96, context=context)[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\"\n",
            "\n",
            "Article:\n",
            "\n",
            "t’s an intense crypto dogfight as dogecoin (DOGE) and shiba inu (SHIB), two of the most popular meme coins, battle it out for the ninth spot on the list of top digital assets by market capitalization. Some traders are profiting from the action by taking spread trades.\n",
            "\n",
            "DOGE has come alive after lagging SHIB by a significant margin earlier this month. The joke cryptocurrency surged to $0.335 on Coinbase on Thursday, hitting the highest level since Aug. 20. It was last trading near $0.30, representing a 22% gain on the day.\n",
            "\n",
            "Meanwhile, SHIB crashed as much as 30% to $0.00006 earlier today, having chalked out a rally to $0.00009 in the seven days to Oct. 27.\n",
            "\n",
            "Summery:\u001b[0m DOGE – long/short/covered strategy\n",
            "\n",
            "Hitting $0.35, the coin has entered bull market conditions. What are the reasons for this massive increase in market value?\n",
            "\n",
            "After $0.30, DOGE has been traded within a downtrend line of the descending trendline which had been forming from July 6. $0.29 is a significant support level for the market. After this, the coin can gain momentum, clearing a level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "g2omRWxDivro",
        "cellView": "form",
        "outputId": "5ebbe9d2-4afe-43a9-e831-be53ce444074"
      },
      "source": [
        "#@title Expand into a script \n",
        "#@markdown The will expand a lead into a script bassed on the opening of pulp fiction.\n",
        "write_script_on_this = \"Feline biology is amazing\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "#@markdown These options don't need to be adjusted.\n",
        "top_p = 0.9 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 512 #@param {type: \"slider\", min:64, max: 2048, step: 64}\n",
        "generate = 1 #@ param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "\n",
        "\n",
        "context = \"\"\"\n",
        "\n",
        "INT. COMPUTER LAB – MORNING\n",
        "\n",
        "A normal computer lab, an office or university, Toronto Canada.\n",
        "It's about 9:00 in the morning. While the place isn't jammed,\n",
        "there's a healthy number of people working, drinking coffee, \n",
        "reading at their computers.\n",
        "\n",
        "Two of these people are a YOUNG MAN and a YOUNG WOMAN. The\n",
        "Young Man has a slight working-class English accent.\n",
        "\n",
        "             YOUNG MAN\n",
        "  I want to tell you about what we've been studying.\n",
        "\n",
        "             YOUNG WOMAN\n",
        "  Oh? What have you been focusing on? \n",
        "\n",
        "             YOUNG MAN\n",
        "  {expand_this}. For example\"\"\"\n",
        "\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=context.format(expand_this = expand_this))[0])\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN8f4mvA97nG",
        "cellView": "form"
      },
      "source": [
        "#@title Make a title sound more academic \n",
        "#@markdown  \n",
        "improve_this = \"we're going ti make an instrument using the potentiometer \" #@param {type:\"string\"}\n",
        "#@markdown - - -\n",
        "top_p = 0.9 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 64 #@ param {type: \"slider\", min:64, max: 2048, step: 64}\n",
        "generate = 12 # @ param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = \"\"\"\n",
        "Instead of saying, \"{improve_this}\" a better shibboleth would be, \\\"\"\"\"\n",
        "\n",
        "#Indie Hackers want to click on titles such as \n",
        "#use something with more punch\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=context.format(improve_this = improve_this))[0].split('\"')[3])\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "Vf63EvRmipH2",
        "outputId": "c544d8f1-4bd9-410d-f020-73c08d183645"
      },
      "source": [
        "#@title Give headlines some more Clickbait \n",
        "improve_this = \"Make an instrument using the a light sensor \" #@param {type:\"string\"}\n",
        "#@markdown - - - - - - - - - - - - - - - - - - - - - - - - \n",
        "top_p = 0.9 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 1 #@ param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 64 # @ param {type: \"slider\", min:64, max: 2048, step: 64}\n",
        "generate = 12 #@ param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = \"\"\"\n",
        "You need to make your title more clickbate. So instead of,\n",
        "\"{improve_this}\" use something with more punch such as,\\\"\"\"\"\n",
        "\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=context.format(improve_this = improve_this))[0].split('\"')[3])\n",
        "                #context=context.format(improve_this = improve_this))[0])\n",
        "\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m [Create a Phone APP that Makes an instrument using the light sensor ]\n",
            "2. You need to make sure your app is reviewed before you can hit publish. So it is best to just sit around on your phone and wait for approval from google rather than just rush to the publish section.\n",
            "3. Make sure your\n",
            "\u001b[0m Make a light controlled Guitar.\n",
            "\u001b[0mCreate a musical instrument using the light sensor\n",
            "\u001b[0m Is your state open to all tools in class?\n",
            "\n",
            "Just a suggestion.\n",
            "\n",
            "06-05-2009, 07:44 PM\n",
            "\n",
            "Angry Player\n",
            "\n",
            "Quote:\n",
            "\n",
            "Originally Posted by otto\n",
            "\n",
            "I might be crazy, but who doesn't want to see their name on an instrument that\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[0m how do I make a musical instrument using an iPhone light sensor.\n",
            "\u001b[0m \n",
            "\u001b[0m \n",
            "\u001b[0m \n",
            "\u001b[0m\n",
            "\n",
            "\u001b[0m How to make an instrument using the a light sensor\n",
            "\u001b[0m Do you have the cash? I'll make you a futuristic laser pistol in _____ hour\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvek96CyOnOh"
      },
      "source": [
        "#@title Generating inference prompts using tracery\n",
        "import tracery\n",
        "from tracery.modifiers import base_english\n",
        "\n",
        "rules = {\n",
        "    \n",
        "    'origin': 'Our team builds #imagine# new online #location# beyond',\n",
        "    'imagine': ['amazing', 'spectaculare' , 'bold', ],\n",
        "    'location': ['worlds', 'spaces', 'colabortion']\n",
        "}\n",
        "\n",
        "grammar = tracery.Grammar(rules)\n",
        "grammar.add_modifiers(base_english)\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=grammar.flatten(\"#origin#\"))[0] + \"\\n\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5cJmv5ALxaM",
        "cellView": "form"
      },
      "source": [
        "#@title Generating grading comment inference prompts using tracery\n",
        "import tracery\n",
        "from tracery.modifiers import base_english\n",
        "\n",
        "rules = {\n",
        "    \n",
        "    'origin': '#this_semester# Jane #does# #good_bad# in class. We hope that she',\n",
        "    'this_semester': ['Our focus this semester was learning to program microcomputers, using sensors, and building electronic circuits.','This semester we focused on learning to build electric circuits, reading information from sensors, and programming microcontrollers.'],\n",
        "    'does': ['works', 'does' , 'particpates', 'performs' ],\n",
        "    'good_bad': ['well', 'competently', 'baddly']\n",
        "}\n",
        "\n",
        "grammar = tracery.Grammar(rules)\n",
        "grammar.add_modifiers(base_english)\n",
        "\n",
        "for x in range(generate):\n",
        "  try:\n",
        "    print(infer(top_p=top_p, \n",
        "                temp=temp, \n",
        "                gen_len=gen_len, \n",
        "                context=grammar.flatten(\"#origin#\"))[0] + \"\\n\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c9FzqkVcZyZ",
        "cellView": "form"
      },
      "source": [
        "#@title Article Generator \n",
        "title = \"Being your own Boss\" #@param {type:\"string\"}\n",
        "site = \"\" #@param {type:\"string\"}\n",
        "date = \"\" #@param {type:\"string\"}\n",
        "author = \"Jim Rohn\" #@param {type:\"string\"}\n",
        "tags = \"goals, drive, gtd\" #@param {type:\"string\"}\n",
        "lead = \"## Table of Content\" #@param {type:\"string\"}\n",
        "#@markdown - - -\n",
        "\n",
        "context = \"\"\"\n",
        "# {title}\n",
        "### Published:{date}\n",
        "### By:{author}\n",
        "##### Tags: {tags}\n",
        "### Site: {site}\n",
        "\n",
        "{lead}\n",
        "\"\"\"\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, \n",
        "              temp=temp, \n",
        "              gen_len=gen_len, \n",
        "              context=context.format(title =title, \n",
        "                                     site = site, \n",
        "                                     date = date, \n",
        "                                     author = author, \n",
        "                                     tags = tags, \n",
        "                                     lead = lead))[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "nKpUf-M554f9"
      },
      "source": [
        "#@title Article generation { form-width: \"300px\" }\n",
        "title = \"COVID-19: What do vaccine passports in Quebec & Ontario mean for Canada's largest provinces? \" #@param {type:\"string\"}\n",
        "site = \"https://www.canada.ca/en/public-health/services/diseases/\" #@param {type:\"string\"}\n",
        "date = \"Sep 7, 2021\" #@param {type:\"string\"}\n",
        "author = \"\" #@param {type:\"string\"}\n",
        "tags = \"COVID-19, Quebec, Ontario, Canada\" #@param {type:\"string\"}\n",
        "lead = \"The passports are certificates that confirm vaccinations and allow people to enjoy eating\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#print(\"Enter/Paste your content. Ctrl-D or Ctrl-Z ( windows ) to save it.\")\n",
        "#context = []\n",
        "#while True:\n",
        "#    try:\n",
        "#        line = input()\n",
        "#    except EOFError:\n",
        "#        break\n",
        "#    context.append(line)\n",
        "\n",
        "context = \"\"\"\n",
        "# {title}\n",
        "### Published:{date}\n",
        "### By:{author}\n",
        "##### Tags: {tags}\n",
        "### Site: {site}\n",
        "\n",
        "{lead}\"\"\"\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, \n",
        "              temp=temp, \n",
        "              gen_len=gen_len, \n",
        "              context=context.format(title =title, \n",
        "                                     site = site, \n",
        "                                     date = date, \n",
        "                                     author = author, \n",
        "                                     tags = tags, \n",
        "                                     lead = lead))[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka8vrZ-kN1Qi"
      },
      "source": [
        "## Code Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiXYadumWbT9"
      },
      "source": [
        "### Set Sampling Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSKHAVCYPt2W"
      },
      "source": [
        "#@markdown ### Leave this alone unless you know what you are doing ... or are just having fun experimenting.\n",
        "#@markdown \n",
        "#@markdown - - - \n",
        "#@markdown Top_p controls diversity/quality. The higher our top_p the more rich and nuanced oir inferences can be.\n",
        "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Temp controls randomnes. Low temps make for mechanical inferences.\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown - - - \n",
        "#@markdown Gen_len adjects the length of text infered.\n",
        "#@markdown Specifcily it adustes the nember of tokens (~4 per engish word).\n",
        "#@markdown\n",
        "#@markdown *Note: Changing gen_len will cause long wait times when first setting lengs that have not been set before.*\n",
        "#@markdown  \n",
        "gen_len = 512 #@param {type: \"slider\", min:64, max: 1024, step: 64}\n",
        "#@markdown - - - \n",
        "#@markdown Generate controls the number of inferences that will be generated.\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIGNc1D7XBQ-"
      },
      "source": [
        "### Python Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "phNf7ZPj3I8U"
      },
      "source": [
        "#@title Python Code - Simple \n",
        "#@markdown Generate code by just writng a comment and a name for a fuction \n",
        "python_comment = \"check if a number is prime or not\" #@param {type:\"string\"}\n",
        "#variable_n_val = \"youtube_video_url\" #@param {type:\"string\"}\n",
        "function_name = \"p\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "context = \"\"\"# {python_comment}\n",
        "\n",
        "def is_\"\"\".format(python_comment = python_comment, \n",
        "           function_name = function_name)\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Gs97bc_DCNIY"
      },
      "source": [
        "#@title Python Code - Complex\n",
        "python_comment = \"detect security flaws \" #@param {type:\"string\"}\n",
        "variable_name =\"person_real_name\" #@param {type:\"string\"}\n",
        "variable_val = \"Isabelle Plante\" #@param {type:\"string\"}\n",
        "function_name = \"online_account_scan\" #@param {type:\"string\"}\n",
        "#@markdown - - -\n",
        "\n",
        "\n",
        "context = '''#!/usr/bin/env python3\n",
        "\n",
        "# {python_comment}\n",
        "\n",
        "{variable_name} = \"{variable_val}\"\n",
        "\n",
        "def {function_name}(n):\n",
        "  \"\"\"This'''.format(python_comment = python_comment,\n",
        "           variable_name = variable_name,\n",
        "           variable_val = variable_val,\n",
        "           function_name = function_name)\n",
        "\n",
        "for x in range(generate):\n",
        "  print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2u9WMX9Q-lG"
      },
      "source": [
        "#@title Vue Code - Simple { form-width: \"500px\" }\n",
        "comment = \"guest speakers\" #@param {type:\"string\"}\n",
        "#variable_n_val = \"youtube_video_url\" #@param {type:\"string\"}\n",
        "name = \"tab_1\" #@param {type:\"string\"}\n",
        "#@markdown - - - \n",
        "#@markdown Leave this alone unless you know ...\n",
        "top_p = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 512 #@param {type:\"slider\", min:64, max:1024, step:64}\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = \"\"\"\n",
        "<!-- Vue template for {comment} page -->\n",
        "<section>\n",
        "  <div id=\"app\" class=\"container\">\n",
        "    <div class=\"content\">\n",
        "      <div id=\"{name} \" class=\"\"\".format(comment = comment, \n",
        "           name = name)\n",
        "      \n",
        "print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb8SkRpDm0rP"
      },
      "source": [
        "#@title Vue Code - Simple { form-width: \"500px\" }\n",
        "comment = \"guest speakers\" #@param {type:\"string\"}\n",
        "#variable_n_val = \"youtube_video_url\" #@param {type:\"string\"}\n",
        "name = \"tab_1\" #@param {type:\"string\"}\n",
        "#@markdown - - - \n",
        "#@markdown Leave this alone unless you know ...\n",
        "top_p = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "gen_len = 512 #@param {type:\"slider\", min:64, max:1024, step:64}\n",
        "generate = 1 #@param {type: \"slider\", min:1, max: 12, step: 1}\n",
        "\n",
        "context = \"\"\"\n",
        "<!-- Vue template for {comment} page -->\n",
        "<section>\n",
        "  <div id=\"app\" class=\"container\">\n",
        "    <div class=\"content\">\n",
        "      <div id=\"{name} \" class=\"\"\".format(comment = comment, \n",
        "           name = name)\n",
        "      \n",
        "print(infer(top_p=top_p, temp=temp, gen_len=gen_len, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xiwQxqCNdz9"
      },
      "source": [
        "# Examples of GPT genereated code.\n",
        "\n",
        "The following are examples of code generated in prior runs.\n",
        "\n",
        "Please paste interesting examples below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgb9xlP394_5"
      },
      "source": [
        "# check if a number is prime or not\n",
        "\n",
        "def is_prime(n):\n",
        "  \"\"\" \n",
        "  > returns true if n is a prime,\n",
        "  > false otherwise.\n",
        "  \"\"\"\n",
        "  for i in range(2, n):\n",
        "    if n % i == 0:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "print(is_prime(7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKo_2bvagu2K"
      },
      "source": [
        "# Program to check if a number is prime or not\n",
        "\n",
        "num = 9\n",
        "\n",
        "# Program to check if a number is prime or not\n",
        "\n",
        "def is_prime(n):\n",
        "    while n > 1:\n",
        "        while n % 2 == 0:\n",
        "            return False\n",
        "        n = n / 2\n",
        "    return True\n",
        "\n",
        "print(\"This is an example of a function that works but is quite wrong!\")\n",
        "\n",
        "for i in range(2, 20):\n",
        "  print(f\"Is {i} prime? {is_prime(i)}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOwWzOgflhW0"
      },
      "source": [
        "# check if a number is prime or not\n",
        "def is_prime(n):\n",
        "    for i in range(2, n):\n",
        "        if n % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "is_prime(9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA5qvTVnS0q8"
      },
      "source": [
        "!pip install grip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXng0F4dSi4i"
      },
      "source": [
        "!pip install grip\n",
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(8000)\"))\n",
        "!grip 8000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shgf_1CZSkI1"
      },
      "source": [
        "!pip install flask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y43hIJmCirQm",
        "outputId": "d60cadf4-2a4b-4c1c-cfd0-8bdaeb8dca8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==0.12.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argcomplete==1.12.3\n",
            "argon2-cffi==21.1.0\n",
            "arviz==0.11.4\n",
            "astor==0.8.1\n",
            "astropy==4.3.1\n",
            "astunparse==1.6.3\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.2.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==4.1.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.3\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.4\n",
            "catalogue==1.0.0\n",
            "certifi==2021.5.30\n",
            "cffi==1.14.6\n",
            "cftime==1.5.1\n",
            "chardet==3.0.4\n",
            "charset-normalizer==2.0.7\n",
            "chex==0.0.8\n",
            "clang==5.0\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.2.7\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.24\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.4\n",
            "distributed==1.25.3\n",
            "dlib @ file:///dlib-19.18.0-cp37-cp37m-linux_x86_64.whl\n",
            "dm-haiku==0.0.5\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.284\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "einops==0.3.2\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\n",
            "entrypoints==0.3\n",
            "ephem==4.1\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.3.0\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.4.0\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.52\n",
            "geopy==1.17.0\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.35.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.6\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.2\n",
            "grpcio==1.34.1\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.2.2\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.6\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "huggingface-hub==0.1.0\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.8.1\n",
            "importlib-resources==5.2.2\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "intel-openmp==2021.4.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.5\n",
            "itsdangerous==1.1.0\n",
            "jax==0.2.12\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda111/jaxlib-0.1.71+cuda111-cp37-none-manylinux2010_x86_64.whl\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "jmp==0.0.2\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.8.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.2\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.5\n",
            "keras==2.6.0\n",
            "keras-nightly==2.5.0.dev2021032900\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.2\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.1\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==2.0.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.3\n",
            "matplotlib-venn==0.11.6\n",
            "mesh-transformer @ file:///content/mesh-transformer-jax\n",
            "missingno==0.5.0\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.10.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.12.2\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.4\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "netCDF4==1.5.7\n",
            "networkx==2.6.3\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.19.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.1\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "optax==0.0.9\n",
            "osqp==0.6.2.post0\n",
            "packaging==21.0\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.5.0\n",
            "panel==0.12.1\n",
            "param==1.11.1\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.2\n",
            "pep517==0.11.0\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==6.2.0\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.5.1\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.5\n",
            "prettytable==2.2.1\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.12.0\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.17.3\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.2.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.4\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.12.0\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.18.0\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.15\n",
            "python-slugify==5.0.2\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "pyviz-comms==2.1.0\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==6.0\n",
            "pyzmq==22.3.0\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.1.1\n",
            "QtPy==1.11.2\n",
            "ray==1.8.0\n",
            "redis==3.5.3\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.5\n",
            "rsa==4.7.2\n",
            "sacremoses==0.0.46\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.4\n",
            "seaborn==0.11.2\n",
            "semver==2.13.0\n",
            "Send2Trash==1.8.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.2.1\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.4.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.25\n",
            "sqlparse==0.4.2\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.6.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.5.0\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.5.0\n",
            "tensorflow-gcs-config==2.6.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==1.2.0\n",
            "tensorflow-probability==0.14.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.12.1\n",
            "testpath==0.5.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "tifffile==2021.10.12\n",
            "tokenizers==0.10.3\n",
            "toml==0.10.2\n",
            "tomli==1.2.1\n",
            "toolz==0.11.1\n",
            "torch @ https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.10.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "tornado==5.1.1\n",
            "tqdm==4.62.3\n",
            "tracery==0.1.1\n",
            "traitlets==5.1.0\n",
            "transformers==4.12.3\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.18.2\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.6.0\n"
          ]
        }
      ]
    }
  ]
}