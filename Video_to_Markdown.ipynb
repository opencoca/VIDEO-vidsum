{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video to Markdown.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/opencoca/vidsum/blob/master/Video_to_Markdown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fJC9jrZrRF_"
      },
      "source": [
        "#VidSum -- Video To Markdown\n",
        "\n",
        "Making it easy for you to convert videos from YouTube, Vimeo and other sources into media-rich Markdown content and summary videos.\n",
        "\n",
        "Media assets can be uploaded to Google Drive, a Github Repo, or simply Downloaded as a Zip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2mKO99zYZ1M",
        "cellView": "form"
      },
      "source": [
        "#@title Connect to Google drive \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#@markdown > \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgkMJtdKrU2-"
      },
      "source": [
        "# Setup Env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gSMYLlotEPEe"
      },
      "source": [
        "#@title Install and setup PyEnv and PipEnv\n",
        "#@markdown \n",
        "#@markdown Pyenv is the perfect solution for developers who want to stay on top of their game and keep multiple Python versions up-to-date. It provides clean, efficient system management without unnecessary package bloat that can otherwise prove cumbersome when dealing with different installations in one environment!\n",
        "#@markdown \n",
        "#@markdown > Note: PyEnv not used at in Colab at this time.\n",
        "#@markdown \n",
        "#@markdown PipEnv is ....\n",
        "\n",
        "!apt-get update -y --quiet > /dev/null\n",
        "!apt-get install -y make build-essential libssl-dev zlib1g-dev \\\n",
        "> libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev\\\n",
        "> libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev python-openssl\\\n",
        "> git > /dev/null\n",
        "\n",
        "!git clone https://github.com/pyenv/pyenv.git ~/.pyenv\n",
        "\n",
        "%env PYENV_ROOT=\"/root/.pyenv\"\n",
        "%env PATH=/root/.pyenv/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
        "\n",
        "%rehashx \n",
        "\n",
        "#!if command -v pyenv >/dev/null; then eval \"$(pyenv init -)\"; fi && pyenv install py --f\n",
        "\n",
        "!pip install pipenv --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shgCLeCzcsVk",
        "cellView": "form"
      },
      "source": [
        "#@title Clone project repo and cd into it...\n",
        "!git clone https://github.com/opencoca/vidsum.git\n",
        "%cd vidsum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPKr50Nfs_ZW"
      },
      "source": [
        "#@title Install project's pipenv and youtube_dl for notebook\n",
        "\n",
        "!pip install youtube_dl\n",
        "import youtube_dl\n",
        "\n",
        "!pipenv install\n",
        "!pipenv install matplotlib google-colab\n",
        "%cd code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ny8qlFwqEu4"
      },
      "source": [
        "# Choose Video From YouTube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "XwV4Lhw5qWvm"
      },
      "source": [
        "youtube_video_url = 'https://www.youtube.com/watch?v=_FRv5hi_z8o' #@param {type:\"string\"}\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzbhMYrrHhX"
      },
      "source": [
        "\n",
        "# Now convert videos and enjoy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctp4gO3tl7OH",
        "cellView": "form"
      },
      "source": [
        "#@title Delete any local files so we can create a fresh doc archive.\n",
        "!rm /content/vidsum/code/*.{jpg,md,mp4,srt,vtt} 2>/dev/null"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaKSnserH2Vy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "0af0b66e-8eef-4aac-fd2e-1ee7cc08463a"
      },
      "source": [
        "#@title Download and process video.\n",
        "\n",
        "#@markdown > Note: This process can take a long time especially on Google Colab. Downloads are at times throttled....\n",
        "#@markdown\n",
        "#@markdown * Videos are downloaded along with their subtiles.\n",
        "#@markdown * Subtitles are analyzed for for important segments.\n",
        "#@markdown * Stills at begining of important segments are extracted.\n",
        "#@markdown * Subtitles are converted to markdown and images are placed into markdown document\n",
        "#@markdown\n",
        "#@markdown > Note: Don't be alarmed by the UnknownBackend error. As long as you end up with a 1.final.en.md in `./vidsum/code` we're golden. :D\n",
        "\n",
        "with youtube_dl.YoutubeDL() as ydl:\n",
        "    info_dict = ydl.extract_info(youtube_video_url, download=False)\n",
        "    video_title = info_dict.get('title', None)\n",
        "\n",
        "print(f'Downloading {video_title}')\n",
        "\n",
        "!pipenv run python ./sum.py -k -u {youtube_video_url} >/dev/null\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] _FRv5hi_z8o: Downloading webpage\n",
            "[youtube] _FRv5hi_z8o: Downloading MPD manifest\n",
            "Downloading CONNECT TO YOUR ROBOT\n",
            "\u001b[0;33mWARNING:\u001b[0m No subtitle format found matching \"srt\" for language en, using vtt\n",
            "Process Process-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"./sum.py\", line 269, in <module>\n",
            "    summary_retrieval_process.join()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"./sum.py\", line 186, in get_summary\n",
            "    regions = find_summary_regions(subtitles, 60, \"english\")\n",
            "  File \"./sum.py\", line 134, in find_summary_regions\n",
            "    summary = summarize(srt_file, n_sentences, language)\n",
            "  File \"./sum.py\", line 47, in summarize\n",
            "    for sentence in summarizer(parser.document, n_sentences):\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/summarizers/lsa.py\", line 38, in __call__\n",
            "    dictionary = self._create_dictionary(document)\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/summarizers/lsa.py\", line 57, in _create_dictionary\n",
            "    words = map(self.normalize_word, document.words)\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/utils.py\", line 39, in decorator\n",
            "    setattr(self, key, getter(self))\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/models/dom/_document.py\", line 33, in words\n",
            "    return tuple(chain(*words))\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/models/dom/_document.py\", line 32, in <genexpr>\n",
            "    words = (p.words for p in self._paragraphs)\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/utils.py\", line 39, in decorator\n",
            "    setattr(self, key, getter(self))\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/models/dom/_paragraph.py\", line 39, in words\n",
            "    return tuple(chain(*(s.words for s in self._sentences)))\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/models/dom/_paragraph.py\", line 39, in <genexpr>\n",
            "    return tuple(chain(*(s.words for s in self._sentences)))\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/utils.py\", line 39, in decorator\n",
            "    setattr(self, key, getter(self))\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/models/dom/_sentence.py\", line 21, in words\n",
            "    return self._tokenizer.to_words(self._text)\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/nlp/tokenizers.py\", line 100, in to_words\n",
            "    words = self._word_tokenizer.tokenize(to_unicode(sentence))\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/sumy/nlp/tokenizers.py\", line 15, in tokenize\n",
            "    return nltk.word_tokenize(text)\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/nltk/tokenize/__init__.py\", line 128, in word_tokenize\n",
            "    sentences = [text] if preserve_line else sent_tokenize(text, language)\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/nltk/tokenize/__init__.py\", line 94, in sent_tokenize\n",
            "    tokenizer = load('tokenizers/punkt/{0}.pickle'.format(language))\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/nltk/data.py\", line 802, in load\n",
            "    resource_url = normalize_resource_url(resource_url)\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/nltk/data.py\", line 201, in normalize_resource_url\n",
            "    name = normalize_resource_name(name, True)\n",
            "  File \"/root/.local/share/virtualenvs/vidsum-GVAHJg4y/lib/python3.7/site-packages/nltk/data.py\", line 235, in normalize_resource_name\n",
            "    is_dir = bool(re.search(r'[\\\\/.]$', resource_name)) or resource_name.endswith(os.path.sep)\n",
            "  File \"/usr/lib/python3.7/re.py\", line 185, in search\n",
            "    return _compile(pattern, flags).search(string)\n",
            "  File \"/usr/lib/python3.7/re.py\", line 275, in _compile\n",
            "    if isinstance(flags, RegexFlag):\n",
            "KeyboardInterrupt\n",
            "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
            "    pid, sts = os.waitpid(self.pid, flag)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iHH4J_ylD01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32404bd9-0655-444e-971f-0022bec37f06"
      },
      "source": [
        "#@title copy Markdown Document:\n",
        "video_title = video_title.replace(\"'\", \"_\")\n",
        "video_title = video_title.replace(\".\", \"\")\n",
        "video_title = video_title.replace(\" \", \"_\")\n",
        "\n",
        "print(f'copying to markdown/{video_title}')\n",
        "!mkdir -p '/content/drive/MyDrive/markdown/{video_title}' &&\\\n",
        "read -t 5 -p 'Pausing for 5 secords to allow GDrive to create folder' &&\\\n",
        "cp /content/vidsum/code/*.jpg '/content/drive/MyDrive/markdown/{video_title}' &&\\\n",
        "cp /content/vidsum/code/*.md '/content/drive/MyDrive/markdown/{video_title}' &&\\\n",
        "cp /content/vidsum/code/*.srt '/content/drive/MyDrive/markdown/{video_title}' &&\\\n",
        "cp /content/vidsum/code/*.vtt '/content/drive/MyDrive/markdown/{video_title}' &&\\\n",
        "cp /content/vidsum/code/*.mp4 '/content/drive/MyDrive/markdown/{video_title}'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copying to markdown/CONNECT_TO_YOUR_ROBOT\n",
            "Pausing for 5 secords to allow GDrive to create folder"
          ]
        }
      ]
    }
  ]
}